"""
TET Bridge Analyzer - Professional Refactored Version
Analyzes TET token bridge transactions between ERC20 and T12 chains.
Identifies inconsistencies, matches transactions, and tracks wallet balances.

Author: Expert Refactoring Team
Version: 2.1
Date: 2025-10-05
"""

import csv
import logging
import os
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta, timezone
from enum import Enum
from pathlib import Path
from threading import Lock
from typing import Dict, List, Optional, Set, Tuple

import pandas as pd
import requests
from dateutil import parser as dateutil_parser
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry


# ==================== CONSTANTS ====================

class Chain(Enum):
    """Blockchain chain types"""
    ERC20 = "ERC20"
    T12 = "T12"


# ==================== CONFIGURATION ====================

@dataclass
class AnalyzerConfig:
    """Configuration parameters for TET Bridge Analyzer"""

    # API Configuration
    etherscan_api_key: str = field(
        default_factory=lambda: os.getenv('ETHERSCAN_API_KEY', 'F2NKDT7435G1M71HWSPX8JRNXH3JXCJPX2')
    )
    bridge_address: str = '0x8f6bc622331f1586cf3ac042efa78b33f72a672d'
    tet_token_address: str = '0x68a47fe1cf42eba4a030a10cd4d6a1031ca3ca0a'

    # Block Configuration
    erc20_start_block: int = 17000000
    latest_block_fallback: int = 25000000
    block_increment_initial: int = 100000
    block_increment_min: int = 10000
    block_increment_max: int = 500000

    # API URLs
    etherscan_base_url: str = "https://api.etherscan.io/v2/api"
    t12_base_url: str = "https://api.explorer.tectum.io/explorer/transactions"

    # Timing Configuration (in seconds)
    timestamp_tolerance: int = 16 * 24 * 60 * 60  # 16 days
    rollback_tolerance: int = 5 * 24 * 60 * 60    # 5 days
    fetch_start_date: datetime = field(
        default_factory=lambda: datetime(2023, 8, 1, 0, 0, 0, tzinfo=timezone.utc)
    )

    # Matching Configuration
    amount_tolerance: float = 0.0001  # Tolerance for amount matching

    # API Rate Limiting
    api_timeout: int = 30
    erc20_rate_limit_delay: float = 0.9
    t12_rate_limit_delay: float = 0.1
    t12_page_size: int = 100

    top_n_wallets: int = 20


    # File Paths
    output_dir: Path = field(default_factory=lambda: Path.cwd())

    def __post_init__(self):
        """Ensure output directory exists"""
        self.output_dir = Path(self.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

    @property
    def erc20_transactions_file(self) -> Path:
        return self.output_dir / "tet_fetch_transactions_erc20.csv"

    @property
    def t12_transactions_file(self) -> Path:
        return self.output_dir / "tet_fetch_transactions_t12.csv"

    @property
    def wallet_balances_file(self) -> Path:
        return self.output_dir / "tet_wallet_bridge_balances.csv"

    @property
    def matched_transactions_file(self) -> Path:
        return self.output_dir / "tet_matched_transactions.csv"

    @property
    def inconsistent_transactions_file(self) -> Path:
        return self.output_dir / "tet_inconsistent_transactions.csv"

    @property
    def erc20_rollback_file(self) -> Path:
        return self.output_dir / "tet_removed_rollback_tx_erc20.csv"

    @property
    def t12_rollback_file(self) -> Path:
        return self.output_dir / "tet_removed_rollback_tx_t12.csv"


# ==================== DATA MODELS ====================

@dataclass
class Transaction:
    """Transaction data model with immutability"""
    hash: str
    signed_amount: float
    date: str
    from_address: str
    to_address: str
    block_number: str = ""
    chain: Chain = None
    parsed_date: Optional[datetime] = None

    def __post_init__(self):
        """Normalize addresses to lowercase"""
        self.from_address = self.from_address.lower()
        self.to_address = self.to_address.lower()
        if isinstance(self.chain, str):
            self.chain = Chain[self.chain]

    def to_dict(self) -> Dict:
        """Convert transaction to dictionary for CSV export"""
        return {
            'blockNumber': self.block_number,
            'hash': self.hash,
            'signed_amount': self.signed_amount,
            'date': self.date,
            'from': self.from_address,
            'to': self.to_address
        }

    def is_zero_amount(self) -> bool:
        """Check if transaction has zero amount"""
        return abs(self.signed_amount) < 1e-8


@dataclass
class WalletBalance:
    """Wallet balance tracking with transaction counts"""
    sent: float = 0.0
    received: float = 0.0
    sent_count: int = 0
    received_count: int = 0

    @property
    def net_balance(self) -> float:
        """Calculate net balance"""
        return self.received - self.sent

    def update_sent(self, amount: float):
        """Update sent balance"""
        self.sent += amount
        self.sent_count += 1

    def update_received(self, amount: float):
        """Update received balance"""
        self.received += amount
        self.received_count += 1


@dataclass
class RollbackPair:
    """Rollback transaction pair data"""
    tx1_hash: str
    tx1_chain: str
    tx1_amount: float
    tx1_date: str
    tx1_from: str
    tx1_to: str
    tx2_hash: str
    tx2_chain: str
    tx2_amount: float
    tx2_date: str
    tx2_from: str
    tx2_to: str
    time_diff_seconds: float
    reason: str

    @property
    def time_diff_minutes(self) -> float:
        """Get time difference in minutes"""
        return self.time_diff_seconds / 60

    def to_dict(self) -> Dict:
        """Convert to dictionary for CSV export"""
        return {
            'tx1_hash': self.tx1_hash,
            'tx1_chain': self.tx1_chain,
            'tx1_amount': self.tx1_amount,
            'tx1_date': self.tx1_date,
            'tx1_from': self.tx1_from,
            'tx1_to': self.tx1_to,
            'tx2_hash': self.tx2_hash,
            'tx2_chain': self.tx2_chain,
            'tx2_amount': self.tx2_amount,
            'tx2_date': self.tx2_date,
            'tx2_from': self.tx2_from,
            'tx2_to': self.tx2_to,
            'time_diff_minutes': self.time_diff_minutes,
            'time_diff_seconds': self.time_diff_seconds,
            'reason': self.reason
        }


# ==================== LOGGING SETUP ====================

class ColoredFormatter(logging.Formatter):
    """Colored log formatter for terminal output"""

    COLORS = {
        'DEBUG': '\033[36m',    # Cyan
        'INFO': '\033[32m',     # Green
        'WARNING': '\033[33m',  # Yellow
        'ERROR': '\033[31m',    # Red
        'CRITICAL': '\033[35m', # Magenta
        'RESET': '\033[0m'      # Reset
    }

    def format(self, record: logging.LogRecord) -> str:
        """Format log record with color"""
        if hasattr(record, 'stream_handler'):
            levelname = record.levelname
            if levelname in self.COLORS:
                record.levelname = f"{self.COLORS[levelname]}{levelname}{self.COLORS['RESET']}"
        return super().format(record)


# Global logger instance to ensure singleton
_logger_instance = None

def get_logger() -> logging.Logger:
    """
    Get or create the singleton logger instance
    This ensures the logger is only configured once
    """
    global _logger_instance

    if _logger_instance is not None:
        return _logger_instance

    log_file = Path('tet_bridge_analyzer.log')
    logger = logging.getLogger('tet_bridge_analyzer')

    # Only configure if not already configured
    if not logger.handlers:
        logger.setLevel(logging.INFO)
        logger.propagate = False

        # Console handler with colors
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_formatter = ColoredFormatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        console_handler.setFormatter(console_formatter)
        console_handler.addFilter(lambda record: setattr(record, 'stream_handler', True) or True)

        # File handler without colors
        file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(file_formatter)

        logger.addHandler(console_handler)
        logger.addHandler(file_handler)

    _logger_instance = logger
    return _logger_instance


# Initialize logger
logger = get_logger()


# ==================== UTILITY FUNCTIONS ====================

class ProgressTracker:
    """Progress tracking utility with visual indicators"""

    @staticmethod
    def print_progress(message: str, current: int = None, total: int = None):
        """Print progress with visual indicators"""
        if current is not None and total is not None and total > 0:
            percentage = (current / total) * 100
            bar_length = 40
            filled_length = int(bar_length * current / total)
            bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)
            print(f"\rüìä {message} |{bar}| {current}/{total} ({percentage:.1f}%)", end='', flush=True)
        else:
            print(f"üìä {message}", flush=True)


class DateTimeParser:
    """Datetime parsing utilities with multiple format support"""

    DATETIME_FORMATS = [
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%dT%H:%M:%S.%f",
        "%Y-%m-%d %H:%M:%S.%f",
        "%Y-%m-%dT%H:%M:%S%z",
        "%Y-%m-%dT%H:%M:%S.%f%z"
    ]

    @classmethod
    def parse_datetime(cls, date_str: str, tx_hash: str = "unknown") -> Optional[datetime]:
        """
        Safely parse datetime strings with timezone awareness

        Args:
            date_str: Date string to parse
            tx_hash: Transaction hash for logging

        Returns:
            Parsed datetime with UTC timezone or None if parsing fails
        """
        if not date_str:
            return None

        try:
            # Clean the date string
            cleaned_date = date_str.replace('Z', '').strip()

            # Try predefined formats first (faster)
            for fmt in cls.DATETIME_FORMATS:
                try:
                    parsed_dt = datetime.strptime(cleaned_date, fmt)
                    # Ensure timezone awareness
                    if parsed_dt.tzinfo is None:
                        parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
                    return parsed_dt
                except ValueError:
                    continue

            # Fallback to dateutil parser
            try:
                parsed_dt = dateutil_parser.parse(cleaned_date)
                if parsed_dt.tzinfo is None:
                    parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
                return parsed_dt
            except Exception:
                pass

            logger.warning(f"Failed to parse datetime for tx {tx_hash}: {date_str}")
            return None

        except Exception as e:
            logger.warning(f"Datetime parsing error for tx {tx_hash}: {e}")
            return None

    @classmethod
    def safe_parse_column(cls, df: pd.DataFrame, column: str) -> pd.Series:
        """
        Safely parse datetime column in DataFrame

        Args:
            df: DataFrame containing the column
            column: Column name to parse

        Returns:
            Series with parsed datetime values
        """
        try:
            return pd.to_datetime(df[column], format='mixed', errors='coerce')
        except Exception:
            try:
                return pd.to_datetime(df[column], format='ISO8601', errors='coerce')
            except Exception:
                try:
                    return pd.to_datetime(df[column], errors='coerce')
                except Exception as e:
                    logger.warning(f"All datetime parsing methods failed for column '{column}': {e}")
                    return df[column]


# ==================== API CLIENT ====================

class APIClient:
    """HTTP API client with retry logic and error handling"""

    def __init__(self, timeout: int = 30, max_retries: int = 3):
        """
        Initialize API client with retry strategy

        Args:
            timeout: Request timeout in seconds
            max_retries: Maximum number of retry attempts
        """
        self.timeout = timeout
        self.session = self._create_session(max_retries)

    def _create_session(self, max_retries: int) -> requests.Session:
        """
        Create requests session with retry strategy

        Args:
            max_retries: Maximum number of retry attempts

        Returns:
            Configured requests session
        """
        session = requests.Session()
        retry_strategy = Retry(
            total=max_retries,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        return session

    def get(self, url: str, params: Dict = None) -> requests.Response:
        """
        Make GET request with error handling

        Args:
            url: Request URL
            params: Query parameters

        Returns:
            Response object

        Raises:
            requests.RequestException: On request failure
        """
        try:
            response = self.session.get(url, params=params, timeout=self.timeout)
            response.raise_for_status()
            return response
        except requests.exceptions.Timeout as e:
            logger.error(f"Request timeout for URL {url}: {e}")
            raise
        except requests.exceptions.RequestException as e:
            logger.error(f"Request failed for URL {url}: {e}")
            raise

    def close(self):
        """Close the session"""
        self.session.close()


# ==================== TRANSACTION FETCHER ====================

class TransactionFetcher:
    """Handles fetching transactions from ERC20 and T12 chains"""

    def __init__(self, config: AnalyzerConfig, api_client: APIClient):
        """
        Initialize transaction fetcher

        Args:
            config: Analyzer configuration
            api_client: API client instance
        """
        self.config = config
        self.api_client = api_client

    def fetch_erc20_transactions(self) -> List[Transaction]:
        """
        Fetch all ERC20 transactions from the bridge

        Returns:
            List of ERC20 transactions
        """
        start_time = time.time()
        print("\nüîç STARTING COMPLETE ERC20 TRANSACTIONS FETCH")
        print("=" * 50)

        all_transactions = []
        latest_block = self._get_latest_block()
        current_block = self.config.erc20_start_block
        block_increment = self.config.block_increment_initial
        total_blocks = latest_block - current_block
        blocks_scanned = 0

        while current_block < latest_block:
            end_block = min(current_block + block_increment, latest_block)
            blocks_in_chunk = end_block - current_block + 1
            blocks_scanned += blocks_in_chunk

            progress_percent = (blocks_scanned / total_blocks) * 100 if total_blocks > 0 else 0
            ProgressTracker.print_progress(
                f"Scanning blocks {current_block:,}-{end_block:,} ({progress_percent:.1f}%)",
                blocks_scanned,
                total_blocks
            )

            try:
                transactions = self._fetch_erc20_block_range(current_block, end_block)

                if transactions:
                    all_transactions.extend(transactions)
                    incoming = sum(1 for tx in transactions if tx.signed_amount > 0)
                    outgoing = sum(1 for tx in transactions if tx.signed_amount < 0)
                    print(f"\r‚úÖ Blocks {current_block:,}-{end_block:,}: "
                          f"{len(transactions)} txs (üìà{incoming} in, üìâ{outgoing} out)")
                    print(f"   üìä Total so far: {len(all_transactions):,} transactions")

                    # Handle pagination if max results reached
                    if len(transactions) >= 10000:
                        print("‚ö†Ô∏è Maximum results reached, splitting block range...")
                        block_increment = max(block_increment // 2, self.config.block_increment_min)
                        blocks_scanned -= blocks_in_chunk
                        continue
                    else:
                        # Increase block increment for efficiency
                        block_increment = min(block_increment * 2, self.config.block_increment_max)

                current_block = end_block + 1
                time.sleep(self.config.erc20_rate_limit_delay)

            except Exception as e:
                logger.error(f"Error fetching blocks {current_block}-{end_block}: {e}")
                block_increment = max(block_increment // 2, self.config.block_increment_min)
                if block_increment < self.config.block_increment_min:
                    current_block = end_block + 1
                    block_increment = self.config.block_increment_initial
                time.sleep(1)  # Back off on error
                continue

        elapsed = time.time() - start_time
        print(f"\nüéâ COMPLETE ERC20 FETCH FINISHED: {len(all_transactions):,} "
              f"transactions in {elapsed:.2f} seconds")

        return all_transactions

    def _get_latest_block(self) -> int:
        """
        Get the latest block number from Etherscan

        Returns:
            Latest block number
        """
        try:
            response = self.api_client.get(
                self.config.etherscan_base_url,
                params={
                    'chainid': '1',
                    'module': 'block',
                    'action': 'getblocknobytime',
                    'timestamp': int(time.time()),
                    'closest': 'before',
                    'apikey': self.config.etherscan_api_key
                }
            )
            result = response.json().get('result')
            if result:
                latest = int(result, 16) if result.startswith('0x') else int(result)
                print(f"Latest block: {latest:,}")
                return latest
        except Exception as e:
            logger.warning(f"Error getting latest block: {e}")

        print(f"Using fallback latest block: {self.config.latest_block_fallback:,}")
        return self.config.latest_block_fallback

    def _fetch_erc20_block_range(self, start_block: int, end_block: int) -> List[Transaction]:
        """
        Fetch ERC20 transactions for a specific block range

        Args:
            start_block: Starting block number
            end_block: Ending block number

        Returns:
            List of transactions in the block range
        """
        params = {
            'chainid': '1',
            'module': 'account',
            'action': 'tokentx',
            'contractaddress': self.config.tet_token_address,
            'address': self.config.bridge_address,
            'startblock': start_block,
            'endblock': end_block,
            'page': 1,
            'offset': 10000,
            'sort': 'asc',
            'apikey': self.config.etherscan_api_key
        }

        response = self.api_client.get(self.config.etherscan_base_url, params=params)
        data = response.json()

        if data.get('status') != '1':
            if data.get('message') != 'No transactions found':
                logger.error(f"Etherscan API error: {data.get('message')}")
            return []

        transactions = []
        for tx_data in data.get('result', []):
            tx = self._process_erc20_transaction(tx_data)
            if tx and not tx.is_zero_amount():
                transactions.append(tx)

        return transactions

    def _process_erc20_transaction(self, tx_data: Dict) -> Optional[Transaction]:
        """
        Process a single ERC20 transaction

        Args:
            tx_data: Raw transaction data from API

        Returns:
            Transaction object or None if invalid
        """
        try:
            # Convert amount from wei to TET
            amount = float(tx_data.get('value', 0))
            decimals = int(tx_data.get('tokenDecimal', 8))
            amount = amount / (10 ** decimals)

            if amount == 0:
                return None

            from_addr = tx_data['from'].lower()
            to_addr = tx_data['to'].lower()
            bridge_addr = self.config.bridge_address.lower()

            # Determine signed amount based on direction
            if to_addr == bridge_addr:
                signed_amount = amount  # Incoming to bridge (deposit)
            elif from_addr == bridge_addr:
                signed_amount = -amount  # Outgoing from bridge (withdrawal)
            else:
                signed_amount = amount

            # Parse timestamp
            timestamp = int(tx_data['timeStamp'])
            timestamp_dt = datetime.fromtimestamp(timestamp, tz=timezone.utc)

            # Filter by start date
            if timestamp_dt < self.config.fetch_start_date:
                return None

            return Transaction(
                hash=tx_data['hash'],
                signed_amount=signed_amount,
                date=timestamp_dt.isoformat(),
                from_address=from_addr,
                to_address=to_addr,
                block_number=tx_data['blockNumber'],
                chain=Chain.ERC20,
                parsed_date=timestamp_dt
            )

        except (KeyError, ValueError, TypeError) as e:
            logger.warning(f"Error processing ERC20 transaction: {e}")
            return None

    def fetch_t12_transactions(self) -> List[Transaction]:
        """
        Fetch all T12 transactions from the bridge

        Returns:
            List of T12 transactions
        """
        start_time = time.time()
        print("\nüîç STARTING T12 TRANSACTIONS FETCH")
        print("=" * 50)

        all_transactions = []
        page = 1
        consecutive_errors = 0
        max_consecutive_errors = 3
        stop_fetching_too_old = False

        while consecutive_errors < max_consecutive_errors:
            try:
                if page % 10 == 0:
                    ProgressTracker.print_progress(f"Fetching T12 page {page}")

                params = {
                    'currencyKey': 'tectum-t12-tet',
                    'address': self.config.bridge_address,
                    'page': page,
                    'limit': self.config.t12_page_size
                }

                response = self.api_client.get(self.config.t12_base_url, params=params)
                data = response.json()

                # Check if we've reached the end
                if data.get('errorCode') != 0 or not data.get('transactions'):
                    print(f"\n‚ÑπÔ∏è No more T12 transactions found at page {page}")
                    break

                page_transactions = []
                for tx_data in data['transactions']:
                    tx = self._process_t12_transaction(tx_data)
                    if tx and not tx.is_zero_amount():
                        page_transactions.append(tx)
                    else:
                        # Stop fetching if transaction is getting older than fetch_start_date
                        parsed_date = DateTimeParser.parse_datetime(tx_data['date'], tx_data['hash'])
                        if parsed_date is not None and parsed_date < self.config.fetch_start_date:
                            stop_fetching_too_old = True
                            break

                all_transactions.extend(page_transactions)

                # Progress update
                if page % 10 == 0:
                    incoming = sum(1 for tx in page_transactions if tx.signed_amount > 0)
                    outgoing = sum(1 for tx in page_transactions if tx.signed_amount < 0)
                    print(f"‚úÖ Page {page-9}-{page}: {len(page_transactions)} txs "
                          f"(üìà{incoming} in, üìâ{outgoing} out) - Total: {len(all_transactions):,}")

                if stop_fetching_too_old is True:
                    print(f"\n‚ÑπÔ∏è No more T12 transactions more recent than {self.config.fetch_start_date.strftime('%Y-%m-%d')}")
                    break

                consecutive_errors = 0  # Reset error counter on success
                page += 1
                time.sleep(self.config.t12_rate_limit_delay)

            except Exception as e:
                consecutive_errors += 1
                logger.error(f"Error fetching T12 transactions page {page} (attempt {consecutive_errors}): {e}")
                if consecutive_errors >= max_consecutive_errors:
                    logger.error("Max consecutive errors reached, stopping T12 fetch")
                    break
                time.sleep(2)  # Back off on error

        elapsed = time.time() - start_time
        print(f"\nüéâ T12 FETCH COMPLETED: {len(all_transactions):,} "
              f"transactions in {elapsed:.2f} seconds")

        return all_transactions

    def _process_t12_transaction(self, tx_data: Dict) -> Optional[Transaction]:
        """
        Process a single T12 transaction

        Args:
            tx_data: Raw transaction data from API

        Returns:
            Transaction object or None if invalid
        """
        try:
            amount = float(tx_data['amount'])

            if amount == 0:
                return None

            from_addr = tx_data['from'].lower()
            to_addr = tx_data['to'].lower()
            bridge_addr = self.config.bridge_address.lower()

            # Determine signed amount
            if to_addr == bridge_addr:
                signed_amount = amount  # Incoming to bridge
            elif from_addr == bridge_addr:
                signed_amount = -amount  # Outgoing from bridge
            else:
                signed_amount = amount

            # Parse date
            parsed_date = DateTimeParser.parse_datetime(tx_data['date'], tx_data['hash'])

            # Filter by start date
            if parsed_date is None or parsed_date < self.config.fetch_start_date:
                return None

            return Transaction(
                hash=tx_data['hash'],
                signed_amount=signed_amount,
                date=parsed_date.isoformat(),
                from_address=from_addr,
                to_address=to_addr,
                block_number=tx_data.get('blockNumber', ''),
                chain=Chain.T12,
                parsed_date=parsed_date
            )

        except (KeyError, ValueError, TypeError) as e:
            logger.warning(f"Error processing T12 transaction: {e}")
            return None


# ==================== TRANSACTION PROCESSOR ====================

class TransactionProcessor:
    """Handles transaction processing, matching, and rollback detection"""

    def __init__(self, config: AnalyzerConfig):
        """
        Initialize transaction processor

        Args:
            config: Analyzer configuration
        """
        self.config = config
        self._amount_precision = 8

    def remove_rollback_transactions(
        self,
        transactions: List[Transaction],
        chain: Chain
    ) -> Tuple[List[Transaction], List[RollbackPair]]:
        """
        Find and remove pairs of rollback transactions within tolerance.

        Algorithm: Sort by date, search forward for matching reverse transactions
        with same amount and reversed addresses.

        Args:
            transactions: List of transactions to analyze
            chain: Chain type for logging

        Returns:
            Tuple of (filtered_transactions, removed_pairs)
        """
        print(f"\nüîç ANALYZING ROLLBACK TRANSACTION PAIRS IN {chain.value}")
        print("=" * 50)
        print(f"‚è±Ô∏è Using {self.config.rollback_tolerance / 60:.0f}-minute tolerance")

        # Parse and sort transactions by date
        transactions_with_date = self._prepare_transactions_for_rollback(transactions)
        print(f"‚úÖ Sorted {len(transactions_with_date):,} transactions by date")

        # Find rollback pairs
        print("üîç Searching for rollback transaction pairs...")
        to_remove, removed_pairs = self._find_rollback_pairs(transactions_with_date, chain)

        # Filter out removed transactions
        transactions_to_keep = [
            tx for i, tx in enumerate(transactions)
            if i not in to_remove
        ]

        self._print_rollback_summary(transactions, transactions_to_keep, removed_pairs, chain)

        return transactions_to_keep, removed_pairs

    def _prepare_transactions_for_rollback(
        self,
        transactions: List[Transaction]
    ) -> List[Tuple[int, Transaction]]:
        """
        Prepare transactions for rollback detection by parsing dates and sorting

        Args:
            transactions: List of transactions

        Returns:
            List of tuples (original_index, transaction) sorted by date
        """
        transactions_with_date = []
        for i, tx in enumerate(transactions):
            if tx.parsed_date is None:
                parsed_date = DateTimeParser.parse_datetime(tx.date, tx.hash)
                if parsed_date:
                    tx.parsed_date = parsed_date
                    transactions_with_date.append((i, tx))
                else:
                    logger.warning(f"Skipping transaction {tx.hash} due to unparseable date")
            else:
                transactions_with_date.append((i, tx))

        transactions_with_date.sort(key=lambda x: x[1].parsed_date)
        return transactions_with_date

    def _find_rollback_pairs(
        self,
        transactions_with_date: List[Tuple[int, Transaction]],
        chain: Chain
    ) -> Tuple[Set[int], List[RollbackPair]]:
        """
        Find rollback transaction pairs

        Args:
            transactions_with_date: Sorted list of (index, transaction) tuples
            chain: Chain type for logging

        Returns:
            Tuple of (indices_to_remove, rollback_pairs)
        """
        to_remove = set()
        removed_pairs = []
        total_to_check = len(transactions_with_date)

        for i, (orig_idx1, tx1) in enumerate(transactions_with_date):
            if orig_idx1 in to_remove:
                continue

            # Progress update
            if (i + 1) % 100 == 0:
                ProgressTracker.print_progress("Checking rollback pairs", i + 1, total_to_check)

            tx1_amount = round(abs(tx1.signed_amount), self._amount_precision)

            # Search forward in time for matches
            for j in range(i + 1, len(transactions_with_date)):
                orig_idx2, tx2 = transactions_with_date[j]

                if orig_idx2 in to_remove:
                    continue

                time_diff = (tx2.parsed_date - tx1.parsed_date).total_seconds()

                # Break if outside tolerance window
                if time_diff > self.config.rollback_tolerance:
                    break

                # Check if this is a rollback pair
                if self._is_rollback_pair(tx1, tx2, tx1_amount):
                    to_remove.add(orig_idx1)
                    to_remove.add(orig_idx2)

                    removed_pairs.append(RollbackPair(
                        tx1_hash=tx1.hash,
                        tx1_chain=chain.value,
                        tx1_amount=tx1.signed_amount,
                        tx1_date=tx1.date,
                        tx1_from=tx1.from_address,
                        tx1_to=tx1.to_address,
                        tx2_hash=tx2.hash,
                        tx2_chain=chain.value,
                        tx2_amount=tx2.signed_amount,
                        tx2_date=tx2.date,
                        tx2_from=tx2.from_address,
                        tx2_to=tx2.to_address,
                        time_diff_seconds=time_diff,
                        reason=f'Rollback transaction pair detected in {chain.value}'
                    ))

                    break  # Stop at first match

        ProgressTracker.print_progress("Checking rollback pairs", total_to_check, total_to_check)
        print()

        return to_remove, removed_pairs

    def _is_rollback_pair(self, tx1: Transaction, tx2: Transaction, tx1_amount: float) -> bool:
        """
        Check if two transactions form a rollback pair

        Args:
            tx1: First transaction
            tx2: Second transaction
            tx1_amount: Rounded amount of first transaction

        Returns:
            True if transactions form a rollback pair
        """
        tx2_amount = round(abs(tx2.signed_amount), self._amount_precision)

        # Check if amounts match within tolerance
        if abs(tx1_amount - tx2_amount) > self.config.amount_tolerance:
            return False

        # Check if addresses are reversed (rollback pattern)
        return (tx1.from_address == tx2.to_address and
                tx1.to_address == tx2.from_address)

    def _print_rollback_summary(
        self,
        original: List[Transaction],
        filtered: List[Transaction],
        pairs: List[RollbackPair],
        chain: Chain
    ):
        """Print rollback analysis summary"""
        print(f"üîÑ {chain.value} rollback pair analysis complete:")
        print(f"   ‚îú‚îÄ Original transactions: {len(original):,}")
        print(f"   ‚îú‚îÄ Rollback pairs found: {len(pairs):,}")
        print(f"   ‚îú‚îÄ Transactions removed: {len(original) - len(filtered):,}")
        print(f"   ‚îî‚îÄ Remaining transactions: {len(filtered):,}")

        if pairs:
            avg_time = sum(p.time_diff_minutes for p in pairs) / len(pairs)
            min_time = min(p.time_diff_minutes for p in pairs)
            max_time = max(p.time_diff_minutes for p in pairs)
            print(f"   üìä Time differences: avg={avg_time:.1f}min, "
                  f"min={min_time:.1f}min, max={max_time:.1f}min")

    def match_transactions(
        self,
        erc20_transactions: List[Transaction],
        t12_transactions: List[Transaction]
    ) -> Tuple[List[Dict], List[Transaction], List[Transaction]]:
        """
        Match transactions between ERC20 and T12 chains

        Args:
            erc20_transactions: List of ERC20 transactions
            t12_transactions: List of T12 transactions

        Returns:
            Tuple of (matched_pairs, erc20_inconsistent, t12_inconsistent)
        """
        start_time = time.time()
        print("\nüîÑ STARTING TRANSACTION MATCHING")
        print("=" * 50)
        print(f"üí° Using amount tolerance: {self.config.amount_tolerance}")

        # Prepare transactions
        print("üìä Step 1: Preparing transactions for matching...")
        erc20_sorted = self._prepare_transactions_for_matching(erc20_transactions, Chain.ERC20)
        t12_sorted = self._prepare_transactions_for_matching(t12_transactions, Chain.T12)

        print(f"‚úÖ Prepared {len(erc20_sorted):,} ERC20 and {len(t12_sorted):,} T12 transactions")

        # Match transactions
        print("üîç Step 2: Matching ERC20 to T12 transactions...")
        matched_pairs, erc20_inconsistent, t12_inconsistent = self._perform_matching(
            erc20_sorted, t12_sorted
        )

        elapsed = time.time() - start_time
        self._print_matching_summary(
            erc20_transactions, t12_transactions,
            matched_pairs, erc20_inconsistent, t12_inconsistent,
            elapsed
        )

        return matched_pairs, erc20_inconsistent, t12_inconsistent

    def _prepare_transactions_for_matching(
        self,
        transactions: List[Transaction],
        chain: Chain
    ) -> List[Transaction]:
        """
        Prepare transactions for matching by parsing dates and sorting

        Args:
            transactions: List of transactions
            chain: Chain type

        Returns:
            Sorted list of transactions with parsed dates
        """
        prepared = []
        for tx in transactions:
            if tx.parsed_date is None:
                parsed_date = DateTimeParser.parse_datetime(tx.date, tx.hash)
                if parsed_date:
                    tx.parsed_date = parsed_date
                    tx.chain = chain
                    prepared.append(tx)
            else:
                tx.chain = chain
                prepared.append(tx)

        prepared.sort(key=lambda x: x.parsed_date)
        return prepared

    def _perform_matching(
        self,
        erc20_sorted: List[Transaction],
        t12_sorted: List[Transaction]
    ) -> Tuple[List[Dict], List[Transaction], List[Transaction]]:
        """
        Perform transaction matching between chains

        Args:
            erc20_sorted: Sorted ERC20 transactions
            t12_sorted: Sorted T12 transactions

        Returns:
            Tuple of (matched_pairs, erc20_inconsistent, t12_inconsistent)
        """
        matched_pairs = []
        erc20_inconsistent = []
        t12_remaining = t12_sorted.copy()

        total_erc20 = len(erc20_sorted)

        for erc20_idx, erc20_tx in enumerate(erc20_sorted):
            # Progress update
            if erc20_idx % 100 == 0:
                ProgressTracker.print_progress(
                    "Processing ERC20 transactions", erc20_idx, total_erc20
                )

            # Find best match in T12
            match_idx, match_tx = self._find_best_match(erc20_tx, t12_remaining)

            if match_idx is not None:
                # Create matched pair
                matched_pairs.append({
                    'erc20_hash': erc20_tx.hash,
                    't12_hash': match_tx.hash,
                    'amount': round(abs(erc20_tx.signed_amount), self._amount_precision),
                    'from_address': erc20_tx.from_address,
                    'to_address': erc20_tx.to_address,
                    'erc20_date': erc20_tx.date,
                    't12_date': match_tx.date
                })
                # Remove matched T12 transaction
                t12_remaining.pop(match_idx)
            else:
                erc20_inconsistent.append(erc20_tx)

        ProgressTracker.print_progress("Processing ERC20 transactions", total_erc20, total_erc20)
        print()

        return matched_pairs, erc20_inconsistent, t12_remaining

    def _find_best_match(
        self,
        erc20_tx: Transaction,
        t12_transactions: List[Transaction]
    ) -> Tuple[Optional[int], Optional[Transaction]]:
        """
        Find the best matching T12 transaction for an ERC20 transaction

        Args:
            erc20_tx: ERC20 transaction to match
            t12_transactions: List of available T12 transactions

        Returns:
            Tuple of (match_index, match_transaction) or (None, None) if no match
        """
        erc20_amount = round(abs(erc20_tx.signed_amount), self._amount_precision)

        # Calculate time window
        min_time = erc20_tx.parsed_date - timedelta(seconds=self.config.timestamp_tolerance)
        max_time = erc20_tx.parsed_date + timedelta(seconds=self.config.timestamp_tolerance)

        best_match_idx = None
        best_time_diff = self.config.timestamp_tolerance

        for t12_idx, t12_tx in enumerate(t12_transactions):
            # Skip if outside time window
            if t12_tx.parsed_date < min_time:
                continue
            if t12_tx.parsed_date > max_time:
                break  # Since sorted, no more matches possible

            # Check if this is a valid match
            if self._is_valid_match(erc20_tx, t12_tx, erc20_amount):
                time_diff = abs((erc20_tx.parsed_date - t12_tx.parsed_date).total_seconds())

                # Update best match if this is closer in time
                if time_diff < best_time_diff:
                    best_match_idx = t12_idx
                    best_time_diff = time_diff

        if best_match_idx is not None:
            return best_match_idx, t12_transactions[best_match_idx]

        return None, None

    def _is_valid_match(
        self,
        erc20_tx: Transaction,
        t12_tx: Transaction,
        erc20_amount: float
    ) -> bool:
        """
        Check if ERC20 and T12 transactions are a valid match

        Args:
            erc20_tx: ERC20 transaction
            t12_tx: T12 transaction
            erc20_amount: Rounded ERC20 amount

        Returns:
            True if transactions match
        """
        t12_amount = round(abs(t12_tx.signed_amount), self._amount_precision)

        # Check amount match within tolerance
        if abs(erc20_amount - t12_amount) >= self.config.amount_tolerance:
            return False

        # Check address match (reversed for bridge transactions)
        return (erc20_tx.from_address == t12_tx.to_address and
                erc20_tx.to_address == t12_tx.from_address)

    def _print_matching_summary(
        self,
        erc20_transactions: List[Transaction],
        t12_transactions: List[Transaction],
        matched_pairs: List[Dict],
        erc20_inconsistent: List[Transaction],
        t12_inconsistent: List[Transaction],
        elapsed: float
    ):
        """Print matching summary statistics"""
        print(f"\nüéâ MATCHING COMPLETED: {len(matched_pairs):,} matches found in {elapsed:.2f} seconds")

        if erc20_transactions:
            match_rate = (len(matched_pairs) / len(erc20_transactions)) * 100
            print(f"üìä ERC20 match rate: {match_rate:.2f}%")

        if t12_transactions:
            match_rate = (len(matched_pairs) / len(t12_transactions)) * 100
            print(f"üìä T12 match rate: {match_rate:.2f}%")

        total_inconsistent = len(erc20_inconsistent) + len(t12_inconsistent)
        print(f"üìä Total inconsistent transactions: {total_inconsistent:,}")
        print(f"   ‚îú‚îÄ ERC20: {len(erc20_inconsistent):,}")
        print(f"   ‚îî‚îÄ T12: {len(t12_inconsistent):,}")


# ==================== WALLET BALANCE CALCULATOR ====================

class WalletBalanceCalculator:
    """Calculate wallet balances excluding rollback transactions"""

    def __init__(self, config: AnalyzerConfig):
        """
        Initialize wallet balance calculator

        Args:
            config: Analyzer configuration
        """
        self.config = config

    def calculate_balances(
        self,
        erc20_transactions: List[Transaction],
        t12_transactions: List[Transaction],
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ) -> Tuple[Dict[str, WalletBalance], Dict[str, WalletBalance]]:
        """
        Calculate wallet balances excluding rollback transactions

        Args:
            erc20_transactions: List of ERC20 transactions
            t12_transactions: List of T12 transactions
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs

        Returns:
            Tuple of (erc20_balances, t12_balances)
        """
        print("\nüí∞ CALCULATING WALLET BALANCES (WITHOUT ROLLBACK TXS)")
        print("=" * 50)

        # Build sets of rollback transaction hashes
        erc20_rollback_hashes = self._build_rollback_hash_set(erc20_removed_pairs)
        t12_rollback_hashes = self._build_rollback_hash_set(t12_removed_pairs)

        # Calculate balances
        erc20_balances = self._calculate_chain_balances(
            erc20_transactions, erc20_rollback_hashes, "ERC20"
        )
        t12_balances = self._calculate_chain_balances(
            t12_transactions, t12_rollback_hashes, "T12"
        )

        return erc20_balances, t12_balances

    def _build_rollback_hash_set(self, rollback_pairs: List[RollbackPair]) -> Set[str]:
        """
        Build set of rollback transaction hashes

        Args:
            rollback_pairs: List of rollback pairs

        Returns:
            Set of transaction hashes
        """
        hashes = set()
        for pair in rollback_pairs:
            hashes.add(pair.tx1_hash)
            hashes.add(pair.tx2_hash)
        return hashes

    def _calculate_chain_balances(
        self,
        transactions: List[Transaction],
        rollback_hashes: Set[str],
        chain_name: str
    ) -> Dict[str, WalletBalance]:
        """
        Calculate balances for a specific chain

        Args:
            transactions: List of transactions
            rollback_hashes: Set of rollback transaction hashes to exclude
            chain_name: Chain name for logging

        Returns:
            Dictionary of wallet balances
        """
        balances = {}
        processed = 0

        for tx in transactions:
            # Skip rollback transactions
            if tx.hash in rollback_hashes:
                continue

            from_addr = tx.from_address
            to_addr = tx.to_address
            amount = abs(tx.signed_amount)

            # Initialize wallet balances if needed
            if from_addr not in balances:
                balances[from_addr] = WalletBalance()
            if to_addr not in balances:
                balances[to_addr] = WalletBalance()

            # Update balances
            balances[from_addr].update_sent(amount)
            balances[to_addr].update_received(amount)

            processed += 1

        print(f"‚úÖ {chain_name}: Processed {processed:,} transactions "
              f"({len(rollback_hashes)} rollback txs excluded)")
        print(f"   ‚îî‚îÄ Tracked {len(balances):,} unique wallets")

        return balances


# ==================== FILE MANAGER ====================

class FileManager:
    """Handles CSV file operations with thread-safe writing"""

    CSV_HEADERS = {
        'transactions': ['blockNumber', 'hash', 'signed_amount', 'date', 'from', 'to'],
        'wallet_balances': [
            'wallet_address', 'erc20_txcount_sent_to_brdg', 'erc20_total_sent_to_brdg',
            'erc20_txcount_received_from_brdg', 'erc20_total_received_from_brdg',
            'erc20_net_balance', 't12_txcnt_sent_to_brdg', 't12_total_sent_to_brdg',
            't12_txcnt_received_from_brdg', 't12_total_received_from_brdg',
            't12_net_balance', 'diff_net_balance'
        ],
        'matched': ['erc20_hash', 't12_hash', 'amount', 'from_address', 'to_address',
                   'erc20_date', 't12_date'],
        'inconsistent': ['chain', 'hash', 'signed_amount', 'date', 'from', 'to', 'reason']
    }

    def __init__(self, config: AnalyzerConfig):
        """
        Initialize file manager

        Args:
            config: Analyzer configuration
        """
        self.config = config
        self.lock = Lock()

    def initialize_csv_files(self):
        """Initialize all CSV files with headers"""
        start_time = time.time()
        print("üìÅ Initializing CSV files...")

        files_config = [
            (self.config.erc20_transactions_file, self.CSV_HEADERS['transactions']),
            (self.config.t12_transactions_file, self.CSV_HEADERS['transactions']),
            (self.config.wallet_balances_file, self.CSV_HEADERS['wallet_balances']),
            (self.config.matched_transactions_file, self.CSV_HEADERS['matched']),
            (self.config.inconsistent_transactions_file, self.CSV_HEADERS['inconsistent'])
        ]

        for filepath, headers in files_config:
            self._initialize_single_file(filepath, headers)

        elapsed = time.time() - start_time
        logger.info(f"üìÅ CSV files initialized (took {elapsed:.2f} seconds)")

    def _initialize_single_file(self, filepath: Path, headers: List[str]):
        """Initialize a single CSV file"""
        if not filepath.exists():
            with open(filepath, 'w', newline='', encoding='utf-8') as f:
                csv.writer(f).writerow(headers)
            print(f"‚úÖ Created {filepath.name}")
        else:
            print(f"üìÇ Found existing {filepath.name}")

    def save_transactions(self, transactions: List[Transaction], filepath: Path):
        """
        Save transactions to CSV file with deduplication and sorting

        Args:
            transactions: List of transactions to save
            filepath: Output file path
        """
        start_time = time.time()

        with self.lock:
            if not transactions:
                print("‚ÑπÔ∏è No transactions to save")
                return

            # Convert to DataFrame
            df = pd.DataFrame([tx.to_dict() for tx in transactions])

            # Remove duplicates by hash
            df = df.drop_duplicates(subset=['hash'], keep='first')

            # Remove zero amounts
            df = df[df['signed_amount'].astype(float).abs() > 1e-8]

            # Sort by date
            df = self._sort_dataframe_by_date(df, 'date', filepath.name)

            # Save to CSV
            df.to_csv(filepath, index=False)
            print(f"üíæ Saved {len(df):,} transactions to {filepath.name}")

        elapsed = time.time() - start_time
        logger.info(f"üíæ Transaction save completed (took {elapsed:.2f} seconds)")

    def _sort_dataframe_by_date(
        self,
        df: pd.DataFrame,
        date_column: str,
        filename: str
    ) -> pd.DataFrame:
        """
        Sort DataFrame by date column with fallback to hash

        Args:
            df: DataFrame to sort
            date_column: Name of date column
            filename: Filename for logging

        Returns:
            Sorted DataFrame
        """
        try:
            df['date_sort'] = DateTimeParser.safe_parse_column(df, date_column)
            df = df.sort_values('date_sort')
            df = df.drop('date_sort', axis=1)
            print(f"‚úÖ Successfully sorted {filename} by date")
        except Exception as e:
            logger.warning(f"Could not sort by date for {filename}: {e}")
            df = df.sort_values('hash')
            print(f"‚ö†Ô∏è Fallback: sorted {filename} by hash")

        return df

    def save_wallet_balances(
        self,
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance]
    ):
        """
        Save combined wallet balances to CSV, sorted by erc20_net_balance

        Args:
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
        """
        start_time = time.time()

        all_wallets = set(erc20_balances.keys()) | set(t12_balances.keys())

        balance_data = []
        for wallet in all_wallets:
            erc20 = erc20_balances.get(wallet, WalletBalance())
            t12 = t12_balances.get(wallet, WalletBalance())

            balance_data.append({
                'wallet_address': wallet,
                'erc20_txcount_sent_to_brdg': erc20.sent_count,
                'erc20_total_sent_to_brdg': erc20.sent,
                'erc20_txcount_received_from_brdg': erc20.received_count,
                'erc20_total_received_from_brdg': erc20.received,
                'erc20_net_balance': erc20.net_balance,
                't12_txcnt_sent_to_brdg': t12.sent_count,
                't12_total_sent_to_brdg': t12.sent,
                't12_txcnt_received_from_brdg': t12.received_count,
                't12_total_received_from_brdg': t12.received,
                't12_net_balance': t12.net_balance,
                'diff_net_balance': erc20.net_balance + t12.net_balance
            })

        df = pd.DataFrame(balance_data)
        # Sort by erc20_net_balance in descending order
        df = df.sort_values('erc20_net_balance', ascending=False)
        df.to_csv(self.config.wallet_balances_file, index=False)

        elapsed = time.time() - start_time
        print(f"üí∞ Saved {len(balance_data):,} combined wallet balances (sorted by erc20_net_balance)")
        logger.info(f"üí∞ Wallet balances saved (took {elapsed:.2f} seconds)")

    def save_matched_transactions(self, matched_pairs: List[Dict]):
        """
        Save matched transaction pairs to CSV

        Args:
            matched_pairs: List of matched transaction pairs
        """
        if not matched_pairs:
            return

        df = pd.DataFrame(matched_pairs)
        df = self._sort_dataframe_by_date(df, 'erc20_date', 'matched transactions')
        df.to_csv(self.config.matched_transactions_file, index=False)
        print(f"‚úÖ Saved {len(matched_pairs):,} matched pairs")

    def save_inconsistent_transactions(self, inconsistent: List[Transaction]):
        """
        Save inconsistent transactions to CSV

        Args:
            inconsistent: List of inconsistent transactions
        """
        start_time = time.time()
        print(f"\nüíæ Processing {len(inconsistent):,} inconsistent transactions...")

        inconsistent_data = []
        for tx in inconsistent:
            opposite_chain = Chain.T12 if tx.chain == Chain.ERC20 else Chain.ERC20
            reason = (f"No matching {opposite_chain.value} transaction found within "
                     f"{self.config.timestamp_tolerance / 60:.0f} min tolerance")

            inconsistent_data.append({
                'chain': tx.chain.value,
                'hash': tx.hash,
                'signed_amount': tx.signed_amount,
                'date': tx.date,
                'from': tx.from_address,
                'to': tx.to_address,
                'reason': reason
            })

        if not inconsistent_data:
            return

        df = pd.DataFrame(inconsistent_data)
        df = df.drop_duplicates(subset=['hash'], keep='first')
        df = self._sort_dataframe_by_date(df, 'date', 'inconsistent transactions')
        df.to_csv(self.config.inconsistent_transactions_file, index=False)

        print(f"‚úÖ Saved {len(df):,} inconsistent transactions")

        # Show breakdown by chain
        erc20_count = len(df[df['chain'] == Chain.ERC20.value])
        t12_count = len(df[df['chain'] == Chain.T12.value])
        print(f"   ‚îú‚îÄ ERC20: {erc20_count:,}")
        print(f"   ‚îî‚îÄ T12: {t12_count:,}")

        elapsed = time.time() - start_time
        logger.info(f"üíæ Inconsistent transactions saved (took {elapsed:.2f} seconds)")

    def save_rollback_pairs(
        self,
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ):
        """
        Save removed rollback pairs to CSV files

        Args:
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs
        """
        if erc20_removed_pairs:
            df = pd.DataFrame([pair.to_dict() for pair in erc20_removed_pairs])
            df.to_csv(self.config.erc20_rollback_file, index=False)
            print(f"üìã Saved {len(erc20_removed_pairs)} ERC20 rollback pairs to "
                  f"{self.config.erc20_rollback_file.name}")

        if t12_removed_pairs:
            df = pd.DataFrame([pair.to_dict() for pair in t12_removed_pairs])
            df.to_csv(self.config.t12_rollback_file, index=False)
            print(f"üìã Saved {len(t12_removed_pairs)} T12 rollback pairs to "
                  f"{self.config.t12_rollback_file.name}")


# ==================== REPORT GENERATOR ====================

class ReportGenerator:
    """Generates comprehensive summary reports"""

    def __init__(self, config: AnalyzerConfig):
        """
        Initialize report generator

        Args:
            config: Analyzer configuration
        """
        self.config = config

    def generate_summary(
        self,
        erc20_count: int,
        t12_count: int,
        matched_count: int,
        inconsistent_count: int,
        erc20_balances: Dict[str, "WalletBalance"],
        t12_balances: Dict[str, "WalletBalance"],
        erc20_rollback_count: int,
        t12_rollback_count: int
    ) -> None:
        """
        Generate comprehensive summary report, including a monthly report
        for the top N wallets.
        """
        print("\n" + "=" * 60)
        print("üìä TET BRIDGE CONSISTENCY REPORT")
        print("=" * 60)

        self._print_bridge_info()
        self._print_explanation()
        self._print_detection_window()
        self._print_output_files()

        self._print_transaction_summary(
            erc20_count,
            t12_count,
            matched_count,
            erc20_rollback_count,
            t12_rollback_count,
        )

        self._print_wallet_analysis("ERC20", erc20_balances)
        self._print_wallet_analysis("T12", t12_balances)

        self._print_bridge_balance_analysis(erc20_balances, t12_balances)

        # Get top N from config, default to 10 if not set (safety)
        top_n = getattr(self.config, 'top_n_wallets', 10)

        # Top N wallets by ERC20 net balance
        top_wallets = self._print_top_wallets(erc20_balances, t12_balances, top_n)

        # Monthly report for top N wallets
        self._print_monthly_top_wallets_report(top_wallets, top_n)

        print("=" * 60)

    def _print_bridge_info(self):
        """Print bridge configuration information"""
        print(f"üåâ Bridge Address: {self.config.bridge_address}")
        print(f"ü™ô TET Token Contract: {self.config.tet_token_address}")
        print("-" * 60)

    def _print_transaction_summary(
        self,
        erc20_count: int,
        t12_count: int,
        matched_count: int,
        erc20_rollback_count: int,
        t12_rollback_count: int
    ):
        """Print transaction summary statistics"""
        erc20_net = erc20_count - erc20_rollback_count
        t12_net = t12_count - t12_rollback_count

        print("üìà TRANSACTION SUMMARY:")
        print(f"‚îú‚îÄ üîó ERC20 transactions: {erc20_net:,} "
              f"(excluded {erc20_rollback_count} rollback txs)")
        print(f"‚îú‚îÄ ‚õìÔ∏è T12 transactions: {t12_net:,} "
              f"(excluded {t12_rollback_count} rollback txs)")
        print(f"‚îú‚îÄ ‚úÖ Successfully matched pairs: {matched_count:,}")

        # Get final inconsistent count from file
        self._print_inconsistent_count()

        # Calculate match rate
        if max(erc20_net, t12_net) > 0:
            match_rate = (matched_count / max(erc20_net, t12_net)) * 100
            print(f"üìä Overall match rate: {match_rate:.2f}%")

        print("-" * 60)

    def _print_inconsistent_count(self):
        """Print inconsistent transaction count"""
        try:
            filepath = self.config.inconsistent_transactions_file
            if filepath.exists():
                df = pd.read_csv(filepath)
                if not df.empty:
                    final_count = len(df)
                    erc20_inc = len(df[df['chain'] == Chain.ERC20.value])
                    t12_inc = len(df[df['chain'] == Chain.T12.value])
                    print(f"‚îî‚îÄ ‚ùå Final inconsistent transactions: {final_count:,}")
                    print(f"   ‚îú‚îÄ ERC20: {erc20_inc:,}")
                    print(f"   ‚îî‚îÄ T12: {t12_inc:,}")
                else:
                    print("‚îî‚îÄ ‚ùå Final inconsistent transactions: 0")
            else:
                print("‚îî‚îÄ ‚ùå Final inconsistent transactions: 0")
        except Exception as e:
            logger.warning(f"Could not read inconsistent transactions file: {e}")
            print("‚îî‚îÄ ‚ùå Inconsistent transactions: (see file)")

    def _print_bridge_balance_analysis(
        self,
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance]
    ):
        """
        Print bridge address balance analysis with explanation

        Args:
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
        """
        bridge_addr = self.config.bridge_address.lower()

        print("\nüåâ BRIDGE ADDRESS BALANCE ANALYSIS:")

        if bridge_addr in erc20_balances or bridge_addr in t12_balances:
            erc20_bal = erc20_balances.get(bridge_addr, WalletBalance())
            t12_bal = t12_balances.get(bridge_addr, WalletBalance())

            diff_net_balance = erc20_bal.net_balance + t12_bal.net_balance

            print(f"‚îú‚îÄ Bridge Address: {self.config.bridge_address}")
            print(f"‚îú‚îÄ ERC20 Net Balance: {erc20_bal.net_balance:.8f} TET")
            print(f"‚îú‚îÄ T12 Net Balance: {t12_bal.net_balance:.8f} TET")
            print(f"‚îî‚îÄ Combined Diff Net Balance: {diff_net_balance:.8f} TET")

            print(f"\nüí° BRIDGE BALANCE EXPLANATION:")
            print(f"   The diff_net_balance represents the difference between what the T12")
            print(f"   bridge received and what the ERC20 bridge sent to wallets, calculated")
            print(f"   from {self.config.fetch_start_date.strftime('%Y-%m-%d')} onwards, after removing all rollback transactions.")
            print(f"   A positive value indicates more TET received on T12 than sent from ERC20.")
            print(f"   A negative value indicates more TET sent from ERC20 than received on T12.")
        else:
            print("‚îî‚îÄ Bridge address not found in balance calculations")

        print("-" * 60)

    def _print_wallet_analysis(self, chain: str, balances: Dict[str, WalletBalance]):
        """
        Print wallet analysis for a specific chain

        Args:
            chain: Chain name
            balances: Wallet balances dictionary
        """
        if not balances:
            return

        total_wallets = len(balances)
        total_sent = sum(bal.sent for bal in balances.values())
        total_received = sum(bal.received for bal in balances.values())
        total_sent_txs = sum(bal.sent_count for bal in balances.values())
        total_received_txs = sum(bal.received_count for bal in balances.values())

        print(f"\nüí∞ {chain} WALLET ANALYSIS:")
        print(f"‚îú‚îÄ üëõ Total unique wallets: {total_wallets:,}")
        print(f"‚îú‚îÄ üì§ Total TET sent from bridge: {total_sent:.8f} ({total_sent_txs:,} txs)")
        print(f"‚îú‚îÄ üì• Total TET received by bridge: {total_received:.8f} ({total_received_txs:,} txs)")
        print(f"‚îî‚îÄ ‚öñÔ∏è Net bridge balance: {total_received - total_sent:.6f}")
        print("-" * 60)

    def _print_top_wallets(
        self,
        erc20_balances: Dict[str, "WalletBalance"],
        t12_balances: Dict[str, "WalletBalance"],
        top_n: int = 10
    ) -> List[str]:
        """
        Print top N wallets by erc20_net_balance (excluding bridge address).

        Args:
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
            top_n: Number of top wallets to retrieve

        Returns:
            List of top-N wallet addresses
        """
        bridge_addr = self.config.bridge_address.lower()

        # Combine all wallets
        all_wallets = set(erc20_balances.keys()) | set(t12_balances.keys())
        all_wallets = all_wallets - {bridge_addr}

        # Create list with erc20_net_balance
        wallet_data: List[Dict[str, float]] = []
        for wallet in all_wallets:
            erc20_bal = erc20_balances.get(wallet, self._empty_wallet_balance())
            wallet_data.append(
                {
                    "address": wallet,
                    "erc20_net_balance": erc20_bal.net_balance,
                }
            )

        # Sort by erc20_net_balance (descending)
        wallet_data.sort(key=lambda x: x["erc20_net_balance"], reverse=True)

        # Get top N
        top_list = wallet_data[:top_n]

        print(f"\nüèÜ TOP {top_n} WALLETS BY ERC20 NET BALANCE (excluding bridge):")

        top_wallet_addresses: List[str] = []

        if top_list:
            for idx, wallet_info in enumerate(top_list, 1):
                addr = wallet_info["address"]
                erc20_net = wallet_info["erc20_net_balance"]

                # Get T12 balance for additional context
                t12_bal = t12_balances.get(addr, self._empty_wallet_balance())
                t12_net = t12_bal.net_balance
                diff_net = erc20_net + t12_net

                print(f"{idx:2d}. {addr}")
                print(f"    ‚îú‚îÄ ERC20 Net: {erc20_net:>15.8f} TET")
                print(f"    ‚îú‚îÄ T12 Net:   {t12_net:>15.8f} TET")
                print(f"    ‚îî‚îÄ Diff Net:  {diff_net:>15.8f} TET")

                top_wallet_addresses.append(addr)
        else:
            print("   No wallets found (excluding bridge address)")

        print("-" * 60)
        return top_wallet_addresses


    def _empty_wallet_balance(self) -> "WalletBalance":
        """
        Helper to create an empty WalletBalance without importing the class here.
        This method assumes WalletBalance is available in the module scope.
        """
        return WalletBalance()


    def _load_rollback_hashes(self, filepath: Path) -> Set[str]:
        """
        Load rollback transaction hashes from a rollback CSV file.

        Args:
            filepath: Path to rollback CSV file

        Returns:
            Set of transaction hashes to exclude
        """
        hashes: Set[str] = set()

        if not filepath.exists():
            return hashes

        try:
            df = pd.read_csv(filepath, usecols=["tx1_hash", "tx2_hash"])
            if "tx1_hash" in df.columns:
                hashes.update(df["tx1_hash"].dropna().astype(str).tolist())
            if "tx2_hash" in df.columns:
                hashes.update(df["tx2_hash"].dropna().astype(str).tolist())
        except Exception as e:
            # Log but do not stop the report generation
            logger.warning(f"Failed to load rollback hashes from {filepath}: {e}")

        return hashes


    def _compute_monthly_net_for_chain(
        self,
        tx_filepath: Path,
        rollback_hashes: Set[str],
        top_wallets: List[str],
        chain_name: str,
    ) -> Optional[pd.DataFrame]:
        """
        Compute monthly net balance (received - sent) per wallet for one chain.

        Args:
            tx_filepath: Path to the chain's transaction CSV
            rollback_hashes: Set of hashes to exclude (rollback txs)
            top_wallets: Wallets to keep
            chain_name: "ERC20" or "T12"

        Returns:
            DataFrame with columns: ["month", "wallet_address", "hain>_net"]
            or None if nothing to report.
        """
        if not tx_filepath.exists():
            return None

        try:
            df = pd.read_csv(tx_filepath)
        except Exception as e:
            logger.warning(f"Failed to read transactions from {tx_filepath}: {e}")
            return None

        if df.empty:
            return None

        required_cols = {"hash", "signed_amount", "date", "from", "to"}
        if not required_cols.issubset(df.columns):
            logger.warning(
                f"File {tx_filepath} does not contain required columns for monthly report"
            )
            return None

        # Exclude rollback txs
        if rollback_hashes:
            df = df[~df["hash"].astype(str).isin(rollback_hashes)]

        if df.empty:
            return None

        # Parse date
        df["parsed_date"] = DateTimeParser.safe_parse_column(df, "date")
        df = df.dropna(subset=["parsed_date"])
        
        if df.empty:
            return None
            
        # FIX: Ensure UTC to normalize data
        df["parsed_date"] = pd.to_datetime(df["parsed_date"], utc=True)

        # FIX: Use strftime instead of to_period to avoid "dropping timezone info" warning
        # This produces "2025-01" strings directly.
        df["month"] = df["parsed_date"].dt.strftime('%Y-%m')

        # Keep only rows involving the top wallets (from or to)
        df = df[df["from"].isin(top_wallets) | df["to"].isin(top_wallets)]
        if df.empty:
            return None

        df["amount_abs"] = df["signed_amount"].astype(float).abs()

        # Sent side
        sent = (
            df.groupby(["month", "from"])["amount_abs"]
            .sum()
            .reset_index()
            .rename(columns={"from": "wallet_address", "amount_abs": "sent"})
        )

        # Received side
        received = (
            df.groupby(["month", "to"])["amount_abs"]
            .sum()
            .reset_index()
            .rename(columns={"to": "wallet_address", "amount_abs": "received"})
        )

        merged = pd.merge(
            sent,
            received,
            on=["month", "wallet_address"],
            how="outer",
        ).fillna(0.0)

        col_name = f"{chain_name.lower()}_net"
        merged[col_name] = merged["received"] - merged["sent"]

        return merged[["month", "wallet_address", col_name]]


    def _print_monthly_top_wallets_report(self, top_wallets: List[str], top_n: int = 10) -> None:
        """
        Print a single aggregated monthly report for the Top N wallets combined.

        Shows ONLY the Total ERC20 Net for the group of top N wallets.
        """
        if not top_wallets:
            return

        print(f"\nüìÖ AGGREGATED MONTHLY REPORT FOR TOP {top_n} WALLETS (ERC20 ONLY):")
        print("=" * 80)

        try:
            erc20_path = self.config.erc20_transactions_file
            erc20_rb_path = self.config.erc20_rollback_file
            erc20_rollback_hashes = self._load_rollback_hashes(erc20_rb_path)

            erc20_monthly = self._compute_monthly_net_for_chain(
                erc20_path, erc20_rollback_hashes, top_wallets, "ERC20"
            )

            if erc20_monthly is None or erc20_monthly.empty:
                print("   (no ERC20 transactions available to build monthly report)")
                return

            # Filter to keep ONLY the Top N wallets
            erc20_monthly = erc20_monthly[erc20_monthly["wallet_address"].isin(top_wallets)]

            if erc20_monthly.empty:
                print("   (no net changes found for top wallets in the period)")
                return

            # Group by month to aggregate
            df_agg = erc20_monthly.groupby("month")[["erc20_net"]].sum().reset_index()

            # Add prices and calculate USD
            monthly_prices = self._get_monthly_average_tet_prices()
            df_agg["tet_price_usd"] = df_agg["month"].map(monthly_prices).fillna(0.0)
            df_agg["erc20_net_usd"] = df_agg["erc20_net"] * df_agg["tet_price_usd"]

            # Sort and Display
            df_agg = df_agg.sort_values("month")

            print(
                f"{'Month':<12} | {'TET Price':>10} | "
                f"{'Total ERC20 Net':>20} | {'Total ERC20 USD':>20}"
            )
            print("-" * 80)

            grand_total_erc20 = 0.0

            for _, row in df_agg.iterrows():
                month = row["month"]
                tet_price = row["tet_price_usd"]
                erc20_net = row["erc20_net"]
                erc20_usd = row["erc20_net_usd"]

                grand_total_erc20 += erc20_net

                print(
                    f"{month:<12} | ${tet_price:>9.4f} | "
                    f"{erc20_net:>20.8f} | ${erc20_usd:>19.2f}"
                )

            print("=" * 80)

            total_usd_historical_erc20 = df_agg["erc20_net_usd"].sum()

            print(
                f"{'CUMULATIVE':<12} | {'(Flows)':>10} | "
                f"{grand_total_erc20:>20.8f} | ${total_usd_historical_erc20:>19.2f}"
            )

            if not df_agg.empty:
                last_price = df_agg.iloc[-1]["tet_price_usd"]
                print("-" * 80)
                print(f"‚ÑπÔ∏è  Current Valuation of Stack (using last price ${last_price:.4f}):")
                print(f"    ${grand_total_erc20 * last_price:,.2f}")

        except Exception as e:
            logger.warning(f"Failed to generate aggregated monthly top wallets report: {e}")
            import traceback
            traceback.print_exc()




    def _print_explanation(self):
        """Print explanation of signed amounts"""
        print("-" * 60)
        print("üí° SIGNED AMOUNTS EXPLANATION:")
        print("‚îú‚îÄ ‚ûï Positive amounts: Incoming to bridge (deposits)")
        print("‚îú‚îÄ ‚ûñ Negative amounts: Outgoing from bridge (withdrawals)")
        print("‚îî‚îÄ üìä This helps identify bridge flow direction")

    def _print_detection_window(self):
        """Print detection window configuration"""
        print("-" * 60)
        print("üîÑ DETECTION WINDOW:")
        print(f"‚îú‚îÄ ‚è±Ô∏è Fetching start date: "
              f"{self.config.fetch_start_date.strftime('%Y/%m/%d %H:%M:%S')}")
        print(f"‚îú‚îÄ ‚è±Ô∏è Matching tolerance: "
              f"{self.config.timestamp_tolerance / 3600:.1f} hours")
        print(f"‚îú‚îÄ ‚è±Ô∏è Rollback tolerance: "
              f"{self.config.rollback_tolerance / 3600:.1f} hours")
        print(f"‚îî‚îÄ üí∞ Amount tolerance: {self.config.amount_tolerance}")

    def _print_output_files(self):
        """Print output file paths"""
        print("-" * 60)
        print("üìÅ OUTPUT FILES:")
        print(f"‚îú‚îÄ üîó ERC20 transactions: {self.config.erc20_transactions_file.name}")
        print(f"‚îú‚îÄ ‚õìÔ∏è T12 transactions: {self.config.t12_transactions_file.name}")
        print(f"‚îú‚îÄ üí∞ Wallet balances: {self.config.wallet_balances_file.name}")
        print(f"‚îú‚îÄ ‚úÖ Matched transactions: {self.config.matched_transactions_file.name}")
        print(f"‚îú‚îÄ ‚ùå Inconsistent transactions: {self.config.inconsistent_transactions_file.name}")
        print(f"‚îî‚îÄ üîÑ Removed rollback pairs: {self.config.erc20_rollback_file.name}, "
              f"{self.config.t12_rollback_file.name}")
        print("-" * 60)


    def _get_monthly_average_tet_prices(self) -> Dict[str, float]:
        """
        Return a dictionary of monthly average TET prices in USD.

        Data sources:
        - 2023: Estimated from IDO ($3.50), market start (~$5-7), and Dec rally (~$30).
        - 2024-2025: Sourced from CoinLore/CoinGecko historical data.

        Returns:
            Dict with keys like "2023-06", "2024-01", etc.
            Values are average USD prices for TET in that month.
        """
        tet_monthly_prices = {
            # 2023 Monthly Average Prices (Reconstructed)
            "2023-06": 3.50,   # IDO Price (Jun 27)
            "2023-07": 5.50,   # Post-launch stability
            "2023-08": 6.25,   # Market adjustment
            "2023-09": 7.80,   # Q3 Growth
            "2023-10": 9.45,   # Q4 Start
            "2023-11": 15.20,  # Pre-rally accumulation
            "2023-12": 29.95,  # Dec rally (Open ~$21, Close ~$38)

            # 2024 Monthly Average Prices
            "2024-01": 42.15,  # Jan 2024: Start $38.62, Close $25.88
            "2024-02": 29.78,  # Feb 2024: Start $25.89, Close $33.66
            "2024-03": 42.35,  # Mar 2024: Start $33.70, Close $51.03
            "2024-04": 33.99,  # Apr 2024: Start $51.03, Close $16.96
            "2024-05": 14.52,  # May 2024: Start $16.96, Close $12.08
            "2024-06": 9.60,   # Jun 2024: Start $12.11, Close $7.48
            "2024-07": 6.81,   # Jul 2024: Start $7.48, Close $6.13
            "2024-08": 7.14,   # Aug 2024: Start $6.13, Close $8.15
            "2024-09": 9.38,   # Sep 2024: Start $8.15, Close $10.60
            "2024-10": 9.46,   # Oct 2024: Start $10.56, Close $8.35
            "2024-11": 9.13,   # Nov 2024: Start $8.37, Close $9.90
            "2024-12": 7.86,   # Dec 2024: Start $9.90, Close $5.81

            # 2025 Monthly Average Prices
            "2025-01": 4.70,   # Jan 2025: Start $5.81, Close $3.58
            "2025-02": 2.67,   # Feb 2025: Start $3.57, Close $1.76
            "2025-03": 1.50,   # Mar 2025: Start $1.77, Close $1.24
            "2025-04": 1.33,   # Apr 2025: Start $1.24, Close $1.42
            "2025-05": 1.21,   # May 2025: Start $1.42, Close $0.99
            "2025-06": 0.71,   # Jun 2025: Start $0.99, Close $0.43
            "2025-07": 0.73,   # Jul 2025: Start $0.43, Close $1.03
            "2025-08": 1.05,   # Aug 2025 (Recovery: High ~$1.27, Low ~$0.84)
            "2025-09": 0.85,   # Sep 2025 (Stable/Bearish: ~$0.85 range)
            "2025-10": 0.90,   # Oct 2025 (Spike to ~$1.00 early month)
            "2025-11": 0.65,   # Nov 2025 (Downtrend: High ~$0.74, Low ~$0.53)
            "2025-12": 0.48,   # Dec 2025 (Current estimate as of Dec 1st)
        }

        return tet_monthly_prices
# ==================== MAIN ANALYZER ====================

class TETBridgeAnalyzer:
    """Main analyzer orchestrating all components"""

    def __init__(self, config: AnalyzerConfig = None):
        """
        Initialize TET Bridge Analyzer

        Args:
            config: Analyzer configuration (uses default if None)
        """
        self.config = config or AnalyzerConfig()
        self.api_client = APIClient(timeout=self.config.api_timeout)
        self.fetcher = TransactionFetcher(self.config, self.api_client)
        self.processor = TransactionProcessor(self.config)
        self.balance_calculator = WalletBalanceCalculator(self.config)
        self.file_manager = FileManager(self.config)
        self.report_generator = ReportGenerator(self.config)

        self._print_startup_banner()

    def _print_startup_banner(self):
        """Print startup banner with configuration info"""
        print("=" * 60)
        print("üöÄ TET BRIDGE ANALYZER STARTING...")
        print("=" * 60)

        logger.info("TET Bridge Analyzer initialized")
        logger.info(f"Bridge address: {self.config.bridge_address}")
        logger.info(f"TET token contract: {self.config.tet_token_address}")
        logger.info(f"Amount tolerance: {self.config.amount_tolerance}")
        logger.info("Amount signs: Positive = incoming, Negative = outgoing")

    def run_analysis(self):
        """Execute the complete analysis pipeline"""
        total_start_time = time.time()
        print("\n" + "=" * 60)
        print("üöÄ TET BRIDGE CONSISTENCY ANALYSIS STARTING")
        print("=" * 60)

        try:
            # Execute analysis steps
            self._step1_initialize_files()
            erc20_txs, t12_txs = self._step2_fetch_transactions()
            matched_pairs, erc20_inconsistent, t12_inconsistent = self._step3_match_transactions(
                erc20_txs, t12_txs
            )
            final_inconsistent, erc20_removed_pairs, t12_removed_pairs = self._step4_detect_rollbacks(
                erc20_inconsistent, t12_inconsistent
            )
            erc20_balances, t12_balances = self._step5_calculate_balances(
                erc20_txs, t12_txs, erc20_removed_pairs, t12_removed_pairs
            )
            self._step6_save_results(
                matched_pairs, final_inconsistent,
                erc20_balances, t12_balances,
                erc20_removed_pairs, t12_removed_pairs
            )
            self._step7_generate_report(
                erc20_txs, t12_txs, matched_pairs, final_inconsistent,
                erc20_balances, t12_balances,
                erc20_removed_pairs, t12_removed_pairs
            )

            # Print completion message
            total_elapsed = time.time() - total_start_time
            print(f"\nüéâ ANALYSIS COMPLETED in {total_elapsed:.2f} seconds")
            print("=" * 60)

        except KeyboardInterrupt:
            print("\n‚ö†Ô∏è Analysis interrupted by user")
            logger.warning("Analysis interrupted by user")
        except Exception as e:
            logger.error(f"Analysis failed: {str(e)}", exc_info=True)
            print(f"\n‚ùå ANALYSIS FAILED: {str(e)}")
            raise
        finally:
            self.api_client.close()

    def _step1_initialize_files(self):
        """Step 1: Initialize CSV files"""
        print("\n")
        print("#" * 50)
        print("üìÅ STEP 1: INITIALIZE CSV FILES")
        print("#" * 50)
        self.file_manager.initialize_csv_files()

    def _step2_fetch_transactions(self) -> Tuple[List[Transaction], List[Transaction]]:
        """
        Step 2: Fetch transactions from both chains

        Returns:
            Tuple of (erc20_transactions, t12_transactions)
        """
        print("\n")
        print("#" * 50)
        print("üì° STEP 2: FETCH TRANSACTIONS")
        print("#" * 50)
        print("üí° Note: Positive amounts = incoming, Negative = outgoing")
        print("üóëÔ∏è Zero amount transactions filtered automatically")

        erc20_txs = self.fetcher.fetch_erc20_transactions()
        t12_txs = self.fetcher.fetch_t12_transactions()

        # Save raw transactions
        self.file_manager.save_transactions(erc20_txs, self.config.erc20_transactions_file)
        self.file_manager.save_transactions(t12_txs, self.config.t12_transactions_file)

        return erc20_txs, t12_txs

    def _step3_match_transactions(
        self,
        erc20_txs: List[Transaction],
        t12_txs: List[Transaction]
    ) -> Tuple[List[Dict], List[Transaction], List[Transaction]]:
        """
        Step 3: Match transactions between chains

        Args:
            erc20_txs: ERC20 transactions
            t12_txs: T12 transactions

        Returns:
            Tuple of (matched_pairs, erc20_inconsistent, t12_inconsistent)
        """
        print("\n")
        print("#" * 50)
        print("üîÑ STEP 3: MATCH TRANSACTIONS")
        print("#" * 50)
        return self.processor.match_transactions(erc20_txs, t12_txs)

    def _step4_detect_rollbacks(
        self,
        erc20_inconsistent: List[Transaction],
        t12_inconsistent: List[Transaction]
    ) -> Tuple[List[Transaction], List[RollbackPair], List[RollbackPair]]:
        """
        Step 4: Detect and remove rollback transactions

        Args:
            erc20_inconsistent: Inconsistent ERC20 transactions
            t12_inconsistent: Inconsistent T12 transactions

        Returns:
            Tuple of (final_inconsistent, erc20_removed_pairs, t12_removed_pairs)
        """
        print("\n")
        print("#" * 50)
        print("üîÑ STEP 4: DETECT AND REMOVE ROLLBACK TRANSACTIONS")
        print("#" * 50)
        erc20_filtered, erc20_removed_pairs = self.processor.remove_rollback_transactions(
            erc20_inconsistent, Chain.ERC20
        )
        t12_filtered, t12_removed_pairs = self.processor.remove_rollback_transactions(
            t12_inconsistent, Chain.T12
        )

        # Combine filtered inconsistent transactions
        final_inconsistent = erc20_filtered + t12_filtered

        print(f"\n‚úÖ Final inconsistent transactions after rollback removal: "
              f"{len(final_inconsistent):,}")
        print(f"   ‚îú‚îÄ ERC20: {len(erc20_filtered):,}")
        print(f"   ‚îî‚îÄ T12: {len(t12_filtered):,}")

        return final_inconsistent, erc20_removed_pairs, t12_removed_pairs

    def _step5_calculate_balances(
        self,
        erc20_txs: List[Transaction],
        t12_txs: List[Transaction],
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ) -> Tuple[Dict[str, WalletBalance], Dict[str, WalletBalance]]:
        """
        Step 5: Calculate wallet balances

        Args:
            erc20_txs: ERC20 transactions
            t12_txs: T12 transactions
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs

        Returns:
            Tuple of (erc20_balances, t12_balances)
        """
        print("\n")
        print("#" * 50)
        print("üí∞ STEP 5: CALCULATE WALLET BALANCES AGAINST BRIDGE")
        print("#" * 50)
        return self.balance_calculator.calculate_balances(
            erc20_txs, t12_txs, erc20_removed_pairs, t12_removed_pairs
        )

    def _step6_save_results(
        self,
        matched_pairs: List[Dict],
        final_inconsistent: List[Transaction],
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance],
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ):
        """
        Step 6: Save all results to files

        Args:
            matched_pairs: Matched transaction pairs
            final_inconsistent: Final inconsistent transactions
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs
        """
        print("\n")
        print("#" * 50)
        print("üíæ STEP 6: SAVE RESULTS")
        print("#" * 50)
        self.file_manager.save_matched_transactions(matched_pairs)
        self.file_manager.save_inconsistent_transactions(final_inconsistent)
        self.file_manager.save_wallet_balances(erc20_balances, t12_balances)
        self.file_manager.save_rollback_pairs(erc20_removed_pairs, t12_removed_pairs)

    def _step7_generate_report(
        self,
        erc20_txs: List[Transaction],
        t12_txs: List[Transaction],
        matched_pairs: List[Dict],
        final_inconsistent: List[Transaction],
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance],
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ):
        """
        Step 7: Generate summary report

        Args:
            erc20_txs: ERC20 transactions
            t12_txs: T12 transactions
            matched_pairs: Matched transaction pairs
            final_inconsistent: Final inconsistent transactions
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs
        """
        print("\n")
        print("#" * 50)
        print("üìä STEP 7: GENERATE REPORT")
        print("#" * 50)
        self.report_generator.generate_summary(
            len(erc20_txs),
            len(t12_txs),
            len(matched_pairs),
            len(final_inconsistent),
            erc20_balances,
            t12_balances,
            len(erc20_removed_pairs) * 2,  # Each pair contains 2 transactions
            len(t12_removed_pairs) * 2
        )


# ==================== MAIN ENTRY POINT ====================

def main():
    """Main execution function"""
    print("üöÄ TET BRIDGE ANALYZER")
    print("=" * 40)

    # Check environment variables
    if not os.getenv('ETHERSCAN_API_KEY'):
        print("‚ö†Ô∏è ETHERSCAN_API_KEY not set - using default (may have rate limits)")
        print("üí° Set ETHERSCAN_API_KEY environment variable for better limits")
    else:
        print("‚úÖ ETHERSCAN_API_KEY found")

    # Initialize and run analyzer
    try:
        config = AnalyzerConfig()
        analyzer = TETBridgeAnalyzer(config)
        analyzer.run_analysis()
    except Exception as e:
        logger.error(f"Fatal error: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
