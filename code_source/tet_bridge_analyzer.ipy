"""
TET Bridge Analyzer 
Analyzes TET token bridge transactions between ERC20 and T12 chains.
Identifies inconsistencies, matches transactions, and tracks wallet balances.

Author: 
Version: 2.1
Date: 2025-10-01
"""

import csv
import logging
import os
import sys
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta, timezone
from enum import Enum
from pathlib import Path
from threading import Lock
from typing import Dict, List, Optional, Set, Tuple

import pandas as pd
import requests
from dateutil import parser as dateutil_parser
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry


# ==================== CONSTANTS ====================

class Chain(Enum):
    """Blockchain chain types"""
    ERC20 = "ERC20"
    T12 = "T12"


# ==================== CONFIGURATION ====================

@dataclass
class AnalyzerConfig:
    """Configuration parameters for TET Bridge Analyzer"""
    
    # API Configuration
    etherscan_api_key: str = field(
        default_factory=lambda: os.getenv('ETHERSCAN_API_KEY', 'F2NKDT7435G1M71HWSPX8JRNXH3JXCJPX2')
    )
    bridge_address: str = '0x8f6bc622331f1586cf3ac042efa78b33f72a672d'
    tet_token_address: str = '0x68a47fe1cf42eba4a030a10cd4d6a1031ca3ca0a'
    
    # Block Configuration
    erc20_start_block: int = 17000000
    latest_block_fallback: int = 25000000
    block_increment_initial: int = 200000
    block_increment_min: int = 10000
    block_increment_max: int = 400000
    
    # API URLs
    etherscan_base_url: str = "https://api.etherscan.io/v2/api"
    t12_base_url: str = "https://api.explorer.tectum.io/explorer/transactions"
    
    # Timing Configuration (in seconds)
    timestamp_tolerance: int = 16 * 24 * 60 * 60  # 16 days
    rollback_tolerance: int = 5 * 24 * 60 * 60    # 5 days
    fetch_start_date: datetime = field(
        default_factory=lambda: datetime(2024, 1, 1, 0, 0, 0, tzinfo=timezone.utc)
    )
    
    # Matching Configuration
    amount_tolerance: float = 0.0001  # Tolerance for amount matching
    
    # API Rate Limiting
    api_timeout: int = 30
    erc20_rate_limit_delay: float = 0.2
    t12_rate_limit_delay: float = 0.1
    t12_page_size: int = 100
    
    # File Paths
    output_dir: Path = field(default_factory=lambda: Path.cwd())
    
    def __post_init__(self):
        """Ensure output directory exists"""
        self.output_dir = Path(self.output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
    
    @property
    def erc20_transactions_file(self) -> Path:
        return self.output_dir / "tet_fetch_transactions_erc20.csv"
    
    @property
    def t12_transactions_file(self) -> Path:
        return self.output_dir / "tet_fetch_transactions_t12.csv"
    
    @property
    def wallet_balances_file(self) -> Path:
        return self.output_dir / "tet_wallet_bridge_balances.csv"
    
    @property
    def matched_transactions_file(self) -> Path:
        return self.output_dir / "tet_matched_transactions.csv"
    
    @property
    def inconsistent_transactions_file(self) -> Path:
        return self.output_dir / "tet_inconsistent_transactions.csv"
    
    @property
    def erc20_rollback_file(self) -> Path:
        return self.output_dir / "tet_removed_rollback_tx_erc20.csv"
    
    @property
    def t12_rollback_file(self) -> Path:
        return self.output_dir / "tet_removed_rollback_tx_t12.csv"


# ==================== DATA MODELS ====================

@dataclass
class Transaction:
    """Transaction data model with immutability"""
    hash: str
    signed_amount: float
    date: str
    from_address: str
    to_address: str
    block_number: str = ""
    chain: Chain = None
    parsed_date: Optional[datetime] = None
    
    def __post_init__(self):
        """Normalize addresses to lowercase"""
        self.from_address = self.from_address.lower()
        self.to_address = self.to_address.lower()
        if isinstance(self.chain, str):
            self.chain = Chain[self.chain]
    
    def to_dict(self) -> Dict:
        """Convert transaction to dictionary for CSV export"""
        return {
            'blockNumber': self.block_number,
            'hash': self.hash,
            'signed_amount': self.signed_amount,
            'date': self.date,
            'from': self.from_address,
            'to': self.to_address
        }
    
    def is_zero_amount(self) -> bool:
        """Check if transaction has zero amount"""
        return abs(self.signed_amount) < 1e-8


@dataclass
class WalletBalance:
    """Wallet balance tracking with transaction counts"""
    sent: float = 0.0
    received: float = 0.0
    sent_count: int = 0
    received_count: int = 0
    
    @property
    def net_balance(self) -> float:
        """Calculate net balance"""
        return self.received - self.sent
    
    def update_sent(self, amount: float):
        """Update sent balance"""
        self.sent += amount
        self.sent_count += 1
    
    def update_received(self, amount: float):
        """Update received balance"""
        self.received += amount
        self.received_count += 1


@dataclass
class RollbackPair:
    """Rollback transaction pair data"""
    tx1_hash: str
    tx1_chain: str
    tx1_amount: float
    tx1_date: str
    tx1_from: str
    tx1_to: str
    tx2_hash: str
    tx2_chain: str
    tx2_amount: float
    tx2_date: str
    tx2_from: str
    tx2_to: str
    time_diff_seconds: float
    reason: str
    
    @property
    def time_diff_minutes(self) -> float:
        """Get time difference in minutes"""
        return self.time_diff_seconds / 60
    
    def to_dict(self) -> Dict:
        """Convert to dictionary for CSV export"""
        return {
            'tx1_hash': self.tx1_hash,
            'tx1_chain': self.tx1_chain,
            'tx1_amount': self.tx1_amount,
            'tx1_date': self.tx1_date,
            'tx1_from': self.tx1_from,
            'tx1_to': self.tx1_to,
            'tx2_hash': self.tx2_hash,
            'tx2_chain': self.tx2_chain,
            'tx2_amount': self.tx2_amount,
            'tx2_date': self.tx2_date,
            'tx2_from': self.tx2_from,
            'tx2_to': self.tx2_to,
            'time_diff_minutes': self.time_diff_minutes,
            'time_diff_seconds': self.time_diff_seconds,
            'reason': self.reason
        }


# ==================== LOGGING SETUP ====================

class ColoredFormatter(logging.Formatter):
    """Colored log formatter for terminal output"""
    
    COLORS = {
        'DEBUG': '\033[36m',    # Cyan
        'INFO': '\033[32m',     # Green
        'WARNING': '\033[33m',  # Yellow
        'ERROR': '\033[31m',    # Red
        'CRITICAL': '\033[35m', # Magenta
        'RESET': '\033[0m'      # Reset
    }
    
    def format(self, record: logging.LogRecord) -> str:
        """Format log record with color"""
        if hasattr(record, 'stream_handler'):
            levelname = record.levelname
            if levelname in self.COLORS:
                record.levelname = f"{self.COLORS[levelname]}{levelname}{self.COLORS['RESET']}"
        return super().format(record)


# Global logger instance to ensure singleton
_logger_instance = None

def get_logger() -> logging.Logger:
    """
    Get or create the singleton logger instance
    This ensures the logger is only configured once
    """
    global _logger_instance
    
    if _logger_instance is not None:
        return _logger_instance
    
    log_file = Path('tet_bridge_analyzer.log')
    logger = logging.getLogger('tet_bridge_analyzer')
    
    # Only configure if not already configured
    if not logger.handlers:
        logger.setLevel(logging.INFO)
        logger.propagate = False
        
        # Console handler with colors
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setLevel(logging.INFO)
        console_formatter = ColoredFormatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        console_handler.setFormatter(console_formatter)
        console_handler.addFilter(lambda record: setattr(record, 'stream_handler', True) or True)
        
        # File handler without colors
        file_handler = logging.FileHandler(log_file, mode='a', encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(file_formatter)
        
        logger.addHandler(console_handler)
        logger.addHandler(file_handler)
    
    _logger_instance = logger
    return _logger_instance


# Initialize logger
logger = get_logger()


# ==================== UTILITY FUNCTIONS ====================

class ProgressTracker:
    """Progress tracking utility with visual indicators"""
    
    @staticmethod
    def print_progress(message: str, current: int = None, total: int = None):
        """Print progress with visual indicators"""
        if current is not None and total is not None and total > 0:
            percentage = (current / total) * 100
            bar_length = 40
            filled_length = int(bar_length * current / total)
            bar = '█' * filled_length + '-' * (bar_length - filled_length)
            print(f"\r📊 {message} |{bar}| {current}/{total} ({percentage:.1f}%)", end='', flush=True)
        else:
            print(f"📊 {message}", flush=True)


class DateTimeParser:
    """Datetime parsing utilities with multiple format support"""
    
    DATETIME_FORMATS = [
        "%Y-%m-%dT%H:%M:%S",
        "%Y-%m-%d %H:%M:%S",
        "%Y-%m-%dT%H:%M:%S.%f",
        "%Y-%m-%d %H:%M:%S.%f",
        "%Y-%m-%dT%H:%M:%S%z",
        "%Y-%m-%dT%H:%M:%S.%f%z"
    ]
    
    @classmethod
    def parse_datetime(cls, date_str: str, tx_hash: str = "unknown") -> Optional[datetime]:
        """
        Safely parse datetime strings with timezone awareness
        
        Args:
            date_str: Date string to parse
            tx_hash: Transaction hash for logging
            
        Returns:
            Parsed datetime with UTC timezone or None if parsing fails
        """
        if not date_str:
            return None
        
        try:
            # Clean the date string
            cleaned_date = date_str.replace('Z', '').strip()
            
            # Try predefined formats first (faster)
            for fmt in cls.DATETIME_FORMATS:
                try:
                    parsed_dt = datetime.strptime(cleaned_date, fmt)
                    # Ensure timezone awareness
                    if parsed_dt.tzinfo is None:
                        parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
                    return parsed_dt
                except ValueError:
                    continue
            
            # Fallback to dateutil parser
            try:
                parsed_dt = dateutil_parser.parse(cleaned_date)
                if parsed_dt.tzinfo is None:
                    parsed_dt = parsed_dt.replace(tzinfo=timezone.utc)
                return parsed_dt
            except Exception:
                pass
            
            logger.warning(f"Failed to parse datetime for tx {tx_hash}: {date_str}")
            return None
            
        except Exception as e:
            logger.warning(f"Datetime parsing error for tx {tx_hash}: {e}")
            return None
    
    @classmethod
    def safe_parse_column(cls, df: pd.DataFrame, column: str) -> pd.Series:
        """
        Safely parse datetime column in DataFrame
        
        Args:
            df: DataFrame containing the column
            column: Column name to parse
            
        Returns:
            Series with parsed datetime values
        """
        try:
            return pd.to_datetime(df[column], format='mixed', errors='coerce')
        except Exception:
            try:
                return pd.to_datetime(df[column], format='ISO8601', errors='coerce')
            except Exception:
                try:
                    return pd.to_datetime(df[column], errors='coerce')
                except Exception as e:
                    logger.warning(f"All datetime parsing methods failed for column '{column}': {e}")
                    return df[column]


# ==================== API CLIENT ====================

class APIClient:
    """HTTP API client with retry logic and error handling"""
    
    def __init__(self, timeout: int = 30, max_retries: int = 3):
        """
        Initialize API client with retry strategy
        
        Args:
            timeout: Request timeout in seconds
            max_retries: Maximum number of retry attempts
        """
        self.timeout = timeout
        self.session = self._create_session(max_retries)
    
    def _create_session(self, max_retries: int) -> requests.Session:
        """
        Create requests session with retry strategy
        
        Args:
            max_retries: Maximum number of retry attempts
            
        Returns:
            Configured requests session
        """
        session = requests.Session()
        retry_strategy = Retry(
            total=max_retries,
            backoff_factor=1,
            status_forcelist=[429, 500, 502, 503, 504],
            allowed_methods=["GET"]
        )
        adapter = HTTPAdapter(max_retries=retry_strategy)
        session.mount("https://", adapter)
        session.mount("http://", adapter)
        return session
    
    def get(self, url: str, params: Dict = None) -> requests.Response:
        """
        Make GET request with error handling
        
        Args:
            url: Request URL
            params: Query parameters
            
        Returns:
            Response object
            
        Raises:
            requests.RequestException: On request failure
        """
        try:
            response = self.session.get(url, params=params, timeout=self.timeout)
            response.raise_for_status()
            return response
        except requests.exceptions.Timeout as e:
            logger.error(f"Request timeout for URL {url}: {e}")
            raise
        except requests.exceptions.RequestException as e:
            logger.error(f"Request failed for URL {url}: {e}")
            raise
    
    def close(self):
        """Close the session"""
        self.session.close()


# ==================== TRANSACTION FETCHER ====================

class TransactionFetcher:
    """Handles fetching transactions from ERC20 and T12 chains"""
    
    def __init__(self, config: AnalyzerConfig, api_client: APIClient):
        """
        Initialize transaction fetcher
        
        Args:
            config: Analyzer configuration
            api_client: API client instance
        """
        self.config = config
        self.api_client = api_client
    
    def fetch_erc20_transactions(self) -> List[Transaction]:
        """
        Fetch all ERC20 transactions from the bridge
        
        Returns:
            List of ERC20 transactions
        """
        start_time = time.time()
        print("\n🔍 STARTING COMPLETE ERC20 TRANSACTIONS FETCH")
        print("=" * 50)
        
        all_transactions = []
        latest_block = self._get_latest_block()
        current_block = self.config.erc20_start_block
        block_increment = self.config.block_increment_initial
        total_blocks = latest_block - current_block
        blocks_scanned = 0
        
        while current_block < latest_block:
            end_block = min(current_block + block_increment, latest_block)
            blocks_in_chunk = end_block - current_block + 1
            blocks_scanned += blocks_in_chunk
            
            progress_percent = (blocks_scanned / total_blocks) * 100 if total_blocks > 0 else 0
            ProgressTracker.print_progress(
                f"Scanning blocks {current_block:,}-{end_block:,} ({progress_percent:.1f}%)",
                blocks_scanned,
                total_blocks
            )
            
            try:
                transactions = self._fetch_erc20_block_range(current_block, end_block)
                
                if transactions:
                    all_transactions.extend(transactions)
                    incoming = sum(1 for tx in transactions if tx.signed_amount > 0)
                    outgoing = sum(1 for tx in transactions if tx.signed_amount < 0)
                    print(f"\r✅ Blocks {current_block:,}-{end_block:,}: "
                          f"{len(transactions)} txs (📈{incoming} in, 📉{outgoing} out)")
                    print(f"   📊 Total so far: {len(all_transactions):,} transactions")
                    
                    # Handle pagination if max results reached
                    if len(transactions) >= 10000:
                        print("⚠️ Maximum results reached, splitting block range...")
                        block_increment = max(block_increment // 2, self.config.block_increment_min)
                        blocks_scanned -= blocks_in_chunk
                        continue
                    else:
                        # Increase block increment for efficiency
                        block_increment = min(block_increment * 2, self.config.block_increment_max)
                
                current_block = end_block + 1
                time.sleep(self.config.erc20_rate_limit_delay)
                
            except Exception as e:
                logger.error(f"Error fetching blocks {current_block}-{end_block}: {e}")
                block_increment = max(block_increment // 2, self.config.block_increment_min)
                if block_increment < self.config.block_increment_min:
                    current_block = end_block + 1
                    block_increment = self.config.block_increment_initial
                time.sleep(1)  # Back off on error
                continue
        
        elapsed = time.time() - start_time
        print(f"\n🎉 COMPLETE ERC20 FETCH FINISHED: {len(all_transactions):,} "
              f"transactions in {elapsed:.2f} seconds")
        
        return all_transactions
    
    def _get_latest_block(self) -> int:
        """
        Get the latest block number from Etherscan
        
        Returns:
            Latest block number
        """
        try:
            response = self.api_client.get(
                self.config.etherscan_base_url,
                params={
                    'chainid': '1',
                    'module': 'block',
                    'action': 'getblocknobytime',
                    'timestamp': int(time.time()),
                    'closest': 'before',
                    'apikey': self.config.etherscan_api_key
                }
            )
            result = response.json().get('result')
            if result:
                latest = int(result, 16) if result.startswith('0x') else int(result)
                print(f"Latest block: {latest:,}")
                return latest
        except Exception as e:
            logger.warning(f"Error getting latest block: {e}")
        
        print(f"Using fallback latest block: {self.config.latest_block_fallback:,}")
        return self.config.latest_block_fallback
    
    def _fetch_erc20_block_range(self, start_block: int, end_block: int) -> List[Transaction]:
        """
        Fetch ERC20 transactions for a specific block range
        
        Args:
            start_block: Starting block number
            end_block: Ending block number
            
        Returns:
            List of transactions in the block range
        """
        params = {
            'chainid': '1',
            'module': 'account',
            'action': 'tokentx',
            'contractaddress': self.config.tet_token_address,
            'address': self.config.bridge_address,
            'startblock': start_block,
            'endblock': end_block,
            'page': 1,
            'offset': 10000,
            'sort': 'asc',
            'apikey': self.config.etherscan_api_key
        }
        
        response = self.api_client.get(self.config.etherscan_base_url, params=params)
        data = response.json()
        
        if data.get('status') != '1':
            if data.get('message') != 'No transactions found':
                logger.error(f"Etherscan API error: {data.get('message')}")
            return []
        
        transactions = []
        for tx_data in data.get('result', []):
            tx = self._process_erc20_transaction(tx_data)
            if tx and not tx.is_zero_amount():
                transactions.append(tx)
        
        return transactions
    
    def _process_erc20_transaction(self, tx_data: Dict) -> Optional[Transaction]:
        """
        Process a single ERC20 transaction
        
        Args:
            tx_data: Raw transaction data from API
            
        Returns:
            Transaction object or None if invalid
        """
        try:
            # Convert amount from wei to TET
            amount = float(tx_data.get('value', 0))
            decimals = int(tx_data.get('tokenDecimal', 8))
            amount = amount / (10 ** decimals)
            
            if amount == 0:
                return None
            
            from_addr = tx_data['from'].lower()
            to_addr = tx_data['to'].lower()
            bridge_addr = self.config.bridge_address.lower()
            
            # Determine signed amount based on direction
            if to_addr == bridge_addr:
                signed_amount = amount  # Incoming to bridge (deposit)
            elif from_addr == bridge_addr:
                signed_amount = -amount  # Outgoing from bridge (withdrawal)
            else:
                signed_amount = amount
            
            # Parse timestamp
            timestamp = int(tx_data['timeStamp'])
            timestamp_dt = datetime.fromtimestamp(timestamp, tz=timezone.utc)
            
            # Filter by start date
            if timestamp_dt < self.config.fetch_start_date:
                return None
            
            return Transaction(
                hash=tx_data['hash'],
                signed_amount=signed_amount,
                date=timestamp_dt.isoformat(),
                from_address=from_addr,
                to_address=to_addr,
                block_number=tx_data['blockNumber'],
                chain=Chain.ERC20,
                parsed_date=timestamp_dt
            )
            
        except (KeyError, ValueError, TypeError) as e:
            logger.warning(f"Error processing ERC20 transaction: {e}")
            return None
    
    def fetch_t12_transactions(self) -> List[Transaction]:
        """
        Fetch all T12 transactions from the bridge
        
        Returns:
            List of T12 transactions
        """
        start_time = time.time()
        print("\n🔍 STARTING T12 TRANSACTIONS FETCH")
        print("=" * 50)
        
        all_transactions = []
        page = 1
        consecutive_errors = 0
        max_consecutive_errors = 3
        stop_fetching_too_old = False
        
        while consecutive_errors < max_consecutive_errors:
            try:
                if page % 10 == 0:
                    ProgressTracker.print_progress(f"Fetching T12 page {page}")
                
                params = {
                    'currencyKey': 'tectum-t12-tet',
                    'address': self.config.bridge_address,
                    'page': page,
                    'limit': self.config.t12_page_size
                }
                
                response = self.api_client.get(self.config.t12_base_url, params=params)
                data = response.json()
                
                # Check if we've reached the end
                if data.get('errorCode') != 0 or not data.get('transactions'):
                    print(f"\nℹ️ No more T12 transactions found at page {page}")
                    break
                
                page_transactions = []
                for tx_data in data['transactions']:
                    tx = self._process_t12_transaction(tx_data)
                    if tx and not tx.is_zero_amount():
                        page_transactions.append(tx)
                    else:
                        # Stop fetching if transaction is getting older than fetch_start_date
                        parsed_date = DateTimeParser.parse_datetime(tx_data['date'], tx_data['hash'])
                        if parsed_date is not None and parsed_date < self.config.fetch_start_date:
                            stop_fetching_too_old = True
                            break
                
                all_transactions.extend(page_transactions)
                
                # Progress update
                if page % 10 == 0:
                    incoming = sum(1 for tx in page_transactions if tx.signed_amount > 0)
                    outgoing = sum(1 for tx in page_transactions if tx.signed_amount < 0)
                    print(f"✅ Page {page-9}-{page}: {len(page_transactions)} txs "
                          f"(📈{incoming} in, 📉{outgoing} out) - Total: {len(all_transactions):,}")
                
                if stop_fetching_too_old is True:
                    print(f"\nℹ️ No more T12 transactions more recent than {self.config.fetch_start_date.strftime('%Y-%m-%d')}")
                    break
                
                consecutive_errors = 0  # Reset error counter on success
                page += 1
                time.sleep(self.config.t12_rate_limit_delay)
                
            except Exception as e:
                consecutive_errors += 1
                logger.error(f"Error fetching T12 transactions page {page} (attempt {consecutive_errors}): {e}")
                if consecutive_errors >= max_consecutive_errors:
                    logger.error("Max consecutive errors reached, stopping T12 fetch")
                    break
                time.sleep(2)  # Back off on error
        
        elapsed = time.time() - start_time
        print(f"\n🎉 T12 FETCH COMPLETED: {len(all_transactions):,} "
              f"transactions in {elapsed:.2f} seconds")
        
        return all_transactions
    
    def _process_t12_transaction(self, tx_data: Dict) -> Optional[Transaction]:
        """
        Process a single T12 transaction
        
        Args:
            tx_data: Raw transaction data from API
            
        Returns:
            Transaction object or None if invalid
        """
        try:
            amount = float(tx_data['amount'])
            
            if amount == 0:
                return None
            
            from_addr = tx_data['from'].lower()
            to_addr = tx_data['to'].lower()
            bridge_addr = self.config.bridge_address.lower()
            
            # Determine signed amount
            if to_addr == bridge_addr:
                signed_amount = amount  # Incoming to bridge
            elif from_addr == bridge_addr:
                signed_amount = -amount  # Outgoing from bridge
            else:
                signed_amount = amount
            
            # Parse date
            parsed_date = DateTimeParser.parse_datetime(tx_data['date'], tx_data['hash'])
            
            # Filter by start date
            if parsed_date is None or parsed_date < self.config.fetch_start_date:
                return None
            
            return Transaction(
                hash=tx_data['hash'],
                signed_amount=signed_amount,
                date=parsed_date.isoformat(),
                from_address=from_addr,
                to_address=to_addr,
                block_number=tx_data.get('blockNumber', ''),
                chain=Chain.T12,
                parsed_date=parsed_date
            )
            
        except (KeyError, ValueError, TypeError) as e:
            logger.warning(f"Error processing T12 transaction: {e}")
            return None


# ==================== TRANSACTION PROCESSOR ====================

class TransactionProcessor:
    """Handles transaction processing, matching, and rollback detection"""
    
    def __init__(self, config: AnalyzerConfig):
        """
        Initialize transaction processor
        
        Args:
            config: Analyzer configuration
        """
        self.config = config
        self._amount_precision = 8
    
    def remove_rollback_transactions(
        self,
        transactions: List[Transaction],
        chain: Chain
    ) -> Tuple[List[Transaction], List[RollbackPair]]:
        """
        Find and remove pairs of rollback transactions within tolerance.
        
        Algorithm: Sort by date, search forward for matching reverse transactions
        with same amount and reversed addresses.
        
        Args:
            transactions: List of transactions to analyze
            chain: Chain type for logging
            
        Returns:
            Tuple of (filtered_transactions, removed_pairs)
        """
        print(f"\n🔍 ANALYZING ROLLBACK TRANSACTION PAIRS IN {chain.value}")
        print("=" * 50)
        print(f"⏱️ Using {self.config.rollback_tolerance / 60:.0f}-minute tolerance")
        
        # Parse and sort transactions by date
        transactions_with_date = self._prepare_transactions_for_rollback(transactions)
        print(f"✅ Sorted {len(transactions_with_date):,} transactions by date")
        
        # Find rollback pairs
        print("🔍 Searching for rollback transaction pairs...")
        to_remove, removed_pairs = self._find_rollback_pairs(transactions_with_date, chain)
        
        # Filter out removed transactions
        transactions_to_keep = [
            tx for i, tx in enumerate(transactions)
            if i not in to_remove
        ]
        
        self._print_rollback_summary(transactions, transactions_to_keep, removed_pairs, chain)
        
        return transactions_to_keep, removed_pairs
    
    def _prepare_transactions_for_rollback(
        self,
        transactions: List[Transaction]
    ) -> List[Tuple[int, Transaction]]:
        """
        Prepare transactions for rollback detection by parsing dates and sorting
        
        Args:
            transactions: List of transactions
            
        Returns:
            List of tuples (original_index, transaction) sorted by date
        """
        transactions_with_date = []
        for i, tx in enumerate(transactions):
            if tx.parsed_date is None:
                parsed_date = DateTimeParser.parse_datetime(tx.date, tx.hash)
                if parsed_date:
                    tx.parsed_date = parsed_date
                    transactions_with_date.append((i, tx))
                else:
                    logger.warning(f"Skipping transaction {tx.hash} due to unparseable date")
            else:
                transactions_with_date.append((i, tx))
        
        transactions_with_date.sort(key=lambda x: x[1].parsed_date)
        return transactions_with_date
    
    def _find_rollback_pairs(
        self,
        transactions_with_date: List[Tuple[int, Transaction]],
        chain: Chain
    ) -> Tuple[Set[int], List[RollbackPair]]:
        """
        Find rollback transaction pairs
        
        Args:
            transactions_with_date: Sorted list of (index, transaction) tuples
            chain: Chain type for logging
            
        Returns:
            Tuple of (indices_to_remove, rollback_pairs)
        """
        to_remove = set()
        removed_pairs = []
        total_to_check = len(transactions_with_date)
        
        for i, (orig_idx1, tx1) in enumerate(transactions_with_date):
            if orig_idx1 in to_remove:
                continue
            
            # Progress update
            if (i + 1) % 100 == 0:
                ProgressTracker.print_progress("Checking rollback pairs", i + 1, total_to_check)
            
            tx1_amount = round(abs(tx1.signed_amount), self._amount_precision)
            
            # Search forward in time for matches
            for j in range(i + 1, len(transactions_with_date)):
                orig_idx2, tx2 = transactions_with_date[j]
                
                if orig_idx2 in to_remove:
                    continue
                
                time_diff = (tx2.parsed_date - tx1.parsed_date).total_seconds()
                
                # Break if outside tolerance window
                if time_diff > self.config.rollback_tolerance:
                    break
                
                # Check if this is a rollback pair
                if self._is_rollback_pair(tx1, tx2, tx1_amount):
                    to_remove.add(orig_idx1)
                    to_remove.add(orig_idx2)
                    
                    removed_pairs.append(RollbackPair(
                        tx1_hash=tx1.hash,
                        tx1_chain=chain.value,
                        tx1_amount=tx1.signed_amount,
                        tx1_date=tx1.date,
                        tx1_from=tx1.from_address,
                        tx1_to=tx1.to_address,
                        tx2_hash=tx2.hash,
                        tx2_chain=chain.value,
                        tx2_amount=tx2.signed_amount,
                        tx2_date=tx2.date,
                        tx2_from=tx2.from_address,
                        tx2_to=tx2.to_address,
                        time_diff_seconds=time_diff,
                        reason=f'Rollback transaction pair detected in {chain.value}'
                    ))
                    
                    break  # Stop at first match
        
        ProgressTracker.print_progress("Checking rollback pairs", total_to_check, total_to_check)
        print()
        
        return to_remove, removed_pairs
    
    def _is_rollback_pair(self, tx1: Transaction, tx2: Transaction, tx1_amount: float) -> bool:
        """
        Check if two transactions form a rollback pair
        
        Args:
            tx1: First transaction
            tx2: Second transaction
            tx1_amount: Rounded amount of first transaction
            
        Returns:
            True if transactions form a rollback pair
        """
        tx2_amount = round(abs(tx2.signed_amount), self._amount_precision)
        
        # Check if amounts match within tolerance
        if abs(tx1_amount - tx2_amount) > self.config.amount_tolerance:
            return False
        
        # Check if addresses are reversed (rollback pattern)
        return (tx1.from_address == tx2.to_address and
                tx1.to_address == tx2.from_address)
    
    def _print_rollback_summary(
        self,
        original: List[Transaction],
        filtered: List[Transaction],
        pairs: List[RollbackPair],
        chain: Chain
    ):
        """Print rollback analysis summary"""
        print(f"🔄 {chain.value} rollback pair analysis complete:")
        print(f"   ├─ Original transactions: {len(original):,}")
        print(f"   ├─ Rollback pairs found: {len(pairs):,}")
        print(f"   ├─ Transactions removed: {len(original) - len(filtered):,}")
        print(f"   └─ Remaining transactions: {len(filtered):,}")
        
        if pairs:
            avg_time = sum(p.time_diff_minutes for p in pairs) / len(pairs)
            min_time = min(p.time_diff_minutes for p in pairs)
            max_time = max(p.time_diff_minutes for p in pairs)
            print(f"   📊 Time differences: avg={avg_time:.1f}min, "
                  f"min={min_time:.1f}min, max={max_time:.1f}min")
    
    def match_transactions(
        self,
        erc20_transactions: List[Transaction],
        t12_transactions: List[Transaction]
    ) -> Tuple[List[Dict], List[Transaction], List[Transaction]]:
        """
        Match transactions between ERC20 and T12 chains
        
        Args:
            erc20_transactions: List of ERC20 transactions
            t12_transactions: List of T12 transactions
            
        Returns:
            Tuple of (matched_pairs, erc20_inconsistent, t12_inconsistent)
        """
        start_time = time.time()
        print("\n🔄 STARTING TRANSACTION MATCHING")
        print("=" * 50)
        print(f"💡 Using amount tolerance: {self.config.amount_tolerance}")
        
        # Prepare transactions
        print("📊 Step 1: Preparing transactions for matching...")
        erc20_sorted = self._prepare_transactions_for_matching(erc20_transactions, Chain.ERC20)
        t12_sorted = self._prepare_transactions_for_matching(t12_transactions, Chain.T12)
        
        print(f"✅ Prepared {len(erc20_sorted):,} ERC20 and {len(t12_sorted):,} T12 transactions")
        
        # Match transactions
        print("🔍 Step 2: Matching ERC20 to T12 transactions...")
        matched_pairs, erc20_inconsistent, t12_inconsistent = self._perform_matching(
            erc20_sorted, t12_sorted
        )
        
        elapsed = time.time() - start_time
        self._print_matching_summary(
            erc20_transactions, t12_transactions,
            matched_pairs, erc20_inconsistent, t12_inconsistent,
            elapsed
        )
        
        return matched_pairs, erc20_inconsistent, t12_inconsistent
    
    def _prepare_transactions_for_matching(
        self,
        transactions: List[Transaction],
        chain: Chain
    ) -> List[Transaction]:
        """
        Prepare transactions for matching by parsing dates and sorting
        
        Args:
            transactions: List of transactions
            chain: Chain type
            
        Returns:
            Sorted list of transactions with parsed dates
        """
        prepared = []
        for tx in transactions:
            if tx.parsed_date is None:
                parsed_date = DateTimeParser.parse_datetime(tx.date, tx.hash)
                if parsed_date:
                    tx.parsed_date = parsed_date
                    tx.chain = chain
                    prepared.append(tx)
            else:
                tx.chain = chain
                prepared.append(tx)
        
        prepared.sort(key=lambda x: x.parsed_date)
        return prepared
    
    def _perform_matching(
        self,
        erc20_sorted: List[Transaction],
        t12_sorted: List[Transaction]
    ) -> Tuple[List[Dict], List[Transaction], List[Transaction]]:
        """
        Perform transaction matching between chains
        
        Args:
            erc20_sorted: Sorted ERC20 transactions
            t12_sorted: Sorted T12 transactions
            
        Returns:
            Tuple of (matched_pairs, erc20_inconsistent, t12_inconsistent)
        """
        matched_pairs = []
        erc20_inconsistent = []
        t12_remaining = t12_sorted.copy()
        
        total_erc20 = len(erc20_sorted)
        
        for erc20_idx, erc20_tx in enumerate(erc20_sorted):
            # Progress update
            if erc20_idx % 100 == 0:
                ProgressTracker.print_progress(
                    "Processing ERC20 transactions", erc20_idx, total_erc20
                )
            
            # Find best match in T12
            match_idx, match_tx = self._find_best_match(erc20_tx, t12_remaining)
            
            if match_idx is not None:
                # Create matched pair
                matched_pairs.append({
                    'erc20_hash': erc20_tx.hash,
                    't12_hash': match_tx.hash,
                    'amount': round(abs(erc20_tx.signed_amount), self._amount_precision),
                    'from_address': erc20_tx.from_address,
                    'to_address': erc20_tx.to_address,
                    'erc20_date': erc20_tx.date,
                    't12_date': match_tx.date
                })
                # Remove matched T12 transaction
                t12_remaining.pop(match_idx)
            else:
                erc20_inconsistent.append(erc20_tx)
        
        ProgressTracker.print_progress("Processing ERC20 transactions", total_erc20, total_erc20)
        print()
        
        return matched_pairs, erc20_inconsistent, t12_remaining
    
    def _find_best_match(
        self,
        erc20_tx: Transaction,
        t12_transactions: List[Transaction]
    ) -> Tuple[Optional[int], Optional[Transaction]]:
        """
        Find the best matching T12 transaction for an ERC20 transaction
        
        Args:
            erc20_tx: ERC20 transaction to match
            t12_transactions: List of available T12 transactions
            
        Returns:
            Tuple of (match_index, match_transaction) or (None, None) if no match
        """
        erc20_amount = round(abs(erc20_tx.signed_amount), self._amount_precision)
        
        # Calculate time window
        min_time = erc20_tx.parsed_date - timedelta(seconds=self.config.timestamp_tolerance)
        max_time = erc20_tx.parsed_date + timedelta(seconds=self.config.timestamp_tolerance)
        
        best_match_idx = None
        best_time_diff = self.config.timestamp_tolerance
        
        for t12_idx, t12_tx in enumerate(t12_transactions):
            # Skip if outside time window
            if t12_tx.parsed_date < min_time:
                continue
            if t12_tx.parsed_date > max_time:
                break  # Since sorted, no more matches possible
            
            # Check if this is a valid match
            if self._is_valid_match(erc20_tx, t12_tx, erc20_amount):
                time_diff = abs((erc20_tx.parsed_date - t12_tx.parsed_date).total_seconds())
                
                # Update best match if this is closer in time
                if time_diff < best_time_diff:
                    best_match_idx = t12_idx
                    best_time_diff = time_diff
        
        if best_match_idx is not None:
            return best_match_idx, t12_transactions[best_match_idx]
        
        return None, None
    
    def _is_valid_match(
        self,
        erc20_tx: Transaction,
        t12_tx: Transaction,
        erc20_amount: float
    ) -> bool:
        """
        Check if ERC20 and T12 transactions are a valid match
        
        Args:
            erc20_tx: ERC20 transaction
            t12_tx: T12 transaction
            erc20_amount: Rounded ERC20 amount
            
        Returns:
            True if transactions match
        """
        t12_amount = round(abs(t12_tx.signed_amount), self._amount_precision)
        
        # Check amount match within tolerance
        if abs(erc20_amount - t12_amount) >= self.config.amount_tolerance:
            return False
        
        # Check address match (reversed for bridge transactions)
        return (erc20_tx.from_address == t12_tx.to_address and
                erc20_tx.to_address == t12_tx.from_address)
    
    def _print_matching_summary(
        self,
        erc20_transactions: List[Transaction],
        t12_transactions: List[Transaction],
        matched_pairs: List[Dict],
        erc20_inconsistent: List[Transaction],
        t12_inconsistent: List[Transaction],
        elapsed: float
    ):
        """Print matching summary statistics"""
        print(f"\n🎉 MATCHING COMPLETED: {len(matched_pairs):,} matches found in {elapsed:.2f} seconds")
        
        if erc20_transactions:
            match_rate = (len(matched_pairs) / len(erc20_transactions)) * 100
            print(f"📊 ERC20 match rate: {match_rate:.2f}%")
        
        if t12_transactions:
            match_rate = (len(matched_pairs) / len(t12_transactions)) * 100
            print(f"📊 T12 match rate: {match_rate:.2f}%")
        
        total_inconsistent = len(erc20_inconsistent) + len(t12_inconsistent)
        print(f"📊 Total inconsistent transactions: {total_inconsistent:,}")
        print(f"   ├─ ERC20: {len(erc20_inconsistent):,}")
        print(f"   └─ T12: {len(t12_inconsistent):,}")


# ==================== WALLET BALANCE CALCULATOR ====================

class WalletBalanceCalculator:
    """Calculate wallet balances excluding rollback transactions"""
    
    def __init__(self, config: AnalyzerConfig):
        """
        Initialize wallet balance calculator
        
        Args:
            config: Analyzer configuration
        """
        self.config = config
    
    def calculate_balances(
        self,
        erc20_transactions: List[Transaction],
        t12_transactions: List[Transaction],
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ) -> Tuple[Dict[str, WalletBalance], Dict[str, WalletBalance]]:
        """
        Calculate wallet balances excluding rollback transactions
        
        Args:
            erc20_transactions: List of ERC20 transactions
            t12_transactions: List of T12 transactions
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs
            
        Returns:
            Tuple of (erc20_balances, t12_balances)
        """
        print("\n💰 CALCULATING WALLET BALANCES (WITHOUT ROLLBACK TXS)")
        print("=" * 50)
        
        # Build sets of rollback transaction hashes
        erc20_rollback_hashes = self._build_rollback_hash_set(erc20_removed_pairs)
        t12_rollback_hashes = self._build_rollback_hash_set(t12_removed_pairs)
        
        # Calculate balances
        erc20_balances = self._calculate_chain_balances(
            erc20_transactions, erc20_rollback_hashes, "ERC20"
        )
        t12_balances = self._calculate_chain_balances(
            t12_transactions, t12_rollback_hashes, "T12"
        )
        
        return erc20_balances, t12_balances
    
    def _build_rollback_hash_set(self, rollback_pairs: List[RollbackPair]) -> Set[str]:
        """
        Build set of rollback transaction hashes
        
        Args:
            rollback_pairs: List of rollback pairs
            
        Returns:
            Set of transaction hashes
        """
        hashes = set()
        for pair in rollback_pairs:
            hashes.add(pair.tx1_hash)
            hashes.add(pair.tx2_hash)
        return hashes
    
    def _calculate_chain_balances(
        self,
        transactions: List[Transaction],
        rollback_hashes: Set[str],
        chain_name: str
    ) -> Dict[str, WalletBalance]:
        """
        Calculate balances for a specific chain
        
        Args:
            transactions: List of transactions
            rollback_hashes: Set of rollback transaction hashes to exclude
            chain_name: Chain name for logging
            
        Returns:
            Dictionary of wallet balances
        """
        balances = {}
        processed = 0
        
        for tx in transactions:
            # Skip rollback transactions
            if tx.hash in rollback_hashes:
                continue
            
            from_addr = tx.from_address
            to_addr = tx.to_address
            amount = abs(tx.signed_amount)
            
            # Initialize wallet balances if needed
            if from_addr not in balances:
                balances[from_addr] = WalletBalance()
            if to_addr not in balances:
                balances[to_addr] = WalletBalance()
            
            # Update balances
            balances[from_addr].update_sent(amount)
            balances[to_addr].update_received(amount)
            
            processed += 1
        
        print(f"✅ {chain_name}: Processed {processed:,} transactions "
              f"({len(rollback_hashes)} rollback txs excluded)")
        print(f"   └─ Tracked {len(balances):,} unique wallets")
        
        return balances


# ==================== FILE MANAGER ====================

class FileManager:
    """Handles CSV file operations with thread-safe writing"""
    
    CSV_HEADERS = {
        'transactions': ['blockNumber', 'hash', 'signed_amount', 'date', 'from', 'to'],
        'wallet_balances': [
            'wallet_address', 'erc20_txcount_sent_to_brdg', 'erc20_total_sent_to_brdg',
            'erc20_txcount_received_from_brdg', 'erc20_total_received_from_brdg',
            'erc20_net_balance', 't12_txcnt_sent_to_brdg', 't12_total_sent_to_brdg',
            't12_txcnt_received_from_brdg', 't12_total_received_from_brdg',
            't12_net_balance', 'diff_net_balance'
        ],
        'matched': ['erc20_hash', 't12_hash', 'amount', 'from_address', 'to_address',
                   'erc20_date', 't12_date'],
        'inconsistent': ['chain', 'hash', 'signed_amount', 'date', 'from', 'to', 'reason']
    }
    
    def __init__(self, config: AnalyzerConfig):
        """
        Initialize file manager
        
        Args:
            config: Analyzer configuration
        """
        self.config = config
        self.lock = Lock()
    
    def initialize_csv_files(self):
        """Initialize all CSV files with headers"""
        start_time = time.time()
        print("📁 Initializing CSV files...")
        
        files_config = [
            (self.config.erc20_transactions_file, self.CSV_HEADERS['transactions']),
            (self.config.t12_transactions_file, self.CSV_HEADERS['transactions']),
            (self.config.wallet_balances_file, self.CSV_HEADERS['wallet_balances']),
            (self.config.matched_transactions_file, self.CSV_HEADERS['matched']),
            (self.config.inconsistent_transactions_file, self.CSV_HEADERS['inconsistent'])
        ]
        
        for filepath, headers in files_config:
            self._initialize_single_file(filepath, headers)
        
        elapsed = time.time() - start_time
        logger.info(f"📁 CSV files initialized (took {elapsed:.2f} seconds)")
    
    def _initialize_single_file(self, filepath: Path, headers: List[str]):
        """Initialize a single CSV file"""
        if not filepath.exists():
            with open(filepath, 'w', newline='', encoding='utf-8') as f:
                csv.writer(f).writerow(headers)
            print(f"✅ Created {filepath.name}")
        else:
            print(f"📂 Found existing {filepath.name}")
    
    def save_transactions(self, transactions: List[Transaction], filepath: Path):
        """
        Save transactions to CSV file with deduplication and sorting
        
        Args:
            transactions: List of transactions to save
            filepath: Output file path
        """
        start_time = time.time()
        
        with self.lock:
            if not transactions:
                print("ℹ️ No transactions to save")
                return
            
            # Convert to DataFrame
            df = pd.DataFrame([tx.to_dict() for tx in transactions])
            
            # Remove duplicates by hash
            df = df.drop_duplicates(subset=['hash'], keep='first')
            
            # Remove zero amounts
            df = df[df['signed_amount'].astype(float).abs() > 1e-8]
            
            # Sort by date
            df = self._sort_dataframe_by_date(df, 'date', filepath.name)
            
            # Save to CSV
            df.to_csv(filepath, index=False)
            print(f"💾 Saved {len(df):,} transactions to {filepath.name}")
        
        elapsed = time.time() - start_time
        logger.info(f"💾 Transaction save completed (took {elapsed:.2f} seconds)")
    
    def _sort_dataframe_by_date(
        self,
        df: pd.DataFrame,
        date_column: str,
        filename: str
    ) -> pd.DataFrame:
        """
        Sort DataFrame by date column with fallback to hash
        
        Args:
            df: DataFrame to sort
            date_column: Name of date column
            filename: Filename for logging
            
        Returns:
            Sorted DataFrame
        """
        try:
            df['date_sort'] = DateTimeParser.safe_parse_column(df, date_column)
            df = df.sort_values('date_sort')
            df = df.drop('date_sort', axis=1)
            print(f"✅ Successfully sorted {filename} by date")
        except Exception as e:
            logger.warning(f"Could not sort by date for {filename}: {e}")
            df = df.sort_values('hash')
            print(f"⚠️ Fallback: sorted {filename} by hash")
        
        return df
    
    def save_wallet_balances(
        self,
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance]
    ):
        """
        Save combined wallet balances to CSV, sorted by erc20_net_balance
        
        Args:
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
        """
        start_time = time.time()
        
        all_wallets = set(erc20_balances.keys()) | set(t12_balances.keys())
        
        balance_data = []
        for wallet in all_wallets:
            erc20 = erc20_balances.get(wallet, WalletBalance())
            t12 = t12_balances.get(wallet, WalletBalance())
            
            balance_data.append({
                'wallet_address': wallet,
                'erc20_txcount_sent_to_brdg': erc20.sent_count,
                'erc20_total_sent_to_brdg': erc20.sent,
                'erc20_txcount_received_from_brdg': erc20.received_count,
                'erc20_total_received_from_brdg': erc20.received,
                'erc20_net_balance': erc20.net_balance,
                't12_txcnt_sent_to_brdg': t12.sent_count,
                't12_total_sent_to_brdg': t12.sent,
                't12_txcnt_received_from_brdg': t12.received_count,
                't12_total_received_from_brdg': t12.received,
                't12_net_balance': t12.net_balance,
                'diff_net_balance': erc20.net_balance + t12.net_balance
            })
        
        df = pd.DataFrame(balance_data)
        # Sort by erc20_net_balance in descending order
        df = df.sort_values('erc20_net_balance', ascending=False)
        df.to_csv(self.config.wallet_balances_file, index=False)
        
        elapsed = time.time() - start_time
        print(f"💰 Saved {len(balance_data):,} combined wallet balances (sorted by erc20_net_balance)")
        logger.info(f"💰 Wallet balances saved (took {elapsed:.2f} seconds)")
    
    def save_matched_transactions(self, matched_pairs: List[Dict]):
        """
        Save matched transaction pairs to CSV
        
        Args:
            matched_pairs: List of matched transaction pairs
        """
        if not matched_pairs:
            return
        
        df = pd.DataFrame(matched_pairs)
        df = self._sort_dataframe_by_date(df, 'erc20_date', 'matched transactions')
        df.to_csv(self.config.matched_transactions_file, index=False)
        print(f"✅ Saved {len(matched_pairs):,} matched pairs")
    
    def save_inconsistent_transactions(self, inconsistent: List[Transaction]):
        """
        Save inconsistent transactions to CSV
        
        Args:
            inconsistent: List of inconsistent transactions
        """
        start_time = time.time()
        print(f"\n💾 Processing {len(inconsistent):,} inconsistent transactions...")
        
        inconsistent_data = []
        for tx in inconsistent:
            opposite_chain = Chain.T12 if tx.chain == Chain.ERC20 else Chain.ERC20
            reason = (f"No matching {opposite_chain.value} transaction found within "
                     f"{self.config.timestamp_tolerance / 60:.0f} min tolerance")
            
            inconsistent_data.append({
                'chain': tx.chain.value,
                'hash': tx.hash,
                'signed_amount': tx.signed_amount,
                'date': tx.date,
                'from': tx.from_address,
                'to': tx.to_address,
                'reason': reason
            })
        
        if not inconsistent_data:
            return
        
        df = pd.DataFrame(inconsistent_data)
        df = df.drop_duplicates(subset=['hash'], keep='first')
        df = self._sort_dataframe_by_date(df, 'date', 'inconsistent transactions')
        df.to_csv(self.config.inconsistent_transactions_file, index=False)
        
        print(f"✅ Saved {len(df):,} inconsistent transactions")
        
        # Show breakdown by chain
        erc20_count = len(df[df['chain'] == Chain.ERC20.value])
        t12_count = len(df[df['chain'] == Chain.T12.value])
        print(f"   ├─ ERC20: {erc20_count:,}")
        print(f"   └─ T12: {t12_count:,}")
        
        elapsed = time.time() - start_time
        logger.info(f"💾 Inconsistent transactions saved (took {elapsed:.2f} seconds)")
    
    def save_rollback_pairs(
        self,
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ):
        """
        Save removed rollback pairs to CSV files
        
        Args:
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs
        """
        if erc20_removed_pairs:
            df = pd.DataFrame([pair.to_dict() for pair in erc20_removed_pairs])
            df.to_csv(self.config.erc20_rollback_file, index=False)
            print(f"📋 Saved {len(erc20_removed_pairs)} ERC20 rollback pairs to "
                  f"{self.config.erc20_rollback_file.name}")
        
        if t12_removed_pairs:
            df = pd.DataFrame([pair.to_dict() for pair in t12_removed_pairs])
            df.to_csv(self.config.t12_rollback_file, index=False)
            print(f"📋 Saved {len(t12_removed_pairs)} T12 rollback pairs to "
                  f"{self.config.t12_rollback_file.name}")


# ==================== REPORT GENERATOR ====================

class ReportGenerator:
    """Generates comprehensive summary reports"""
    
    def __init__(self, config: AnalyzerConfig):
        """
        Initialize report generator
        
        Args:
            config: Analyzer configuration
        """
        self.config = config
    
    def generate_summary(
        self,
        erc20_count: int,
        t12_count: int,
        matched_count: int,
        inconsistent_count: int,
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance],
        erc20_rollback_count: int,
        t12_rollback_count: int
    ):
        """
        Generate comprehensive summary report
        
        Args:
            erc20_count: Total ERC20 transactions
            t12_count: Total T12 transactions
            matched_count: Number of matched pairs
            inconsistent_count: Number of inconsistent transactions
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
            erc20_rollback_count: Number of ERC20 rollback transactions
            t12_rollback_count: Number of T12 rollback transactions
        """
        print("\n" + "=" * 60)
        print("📊 TET BRIDGE CONSISTENCY REPORT")
        print("=" * 60)
        
        self._print_bridge_info()
        self._print_explanation()
        self._print_detection_window()
        self._print_output_files()
        
        self._print_transaction_summary(
            erc20_count, t12_count, matched_count,
            erc20_rollback_count, t12_rollback_count
        )
        
        self._print_wallet_analysis("ERC20", erc20_balances)
        self._print_wallet_analysis("T12", t12_balances)
        
        self._print_bridge_balance_analysis(erc20_balances, t12_balances)
        self._print_top_wallets(erc20_balances, t12_balances)
        

        
        print("=" * 60)
    
    def _print_bridge_info(self):
        """Print bridge configuration information"""
        print(f"🌉 Bridge Address: {self.config.bridge_address}")
        print(f"🪙 TET Token Contract: {self.config.tet_token_address}")
        print("-" * 60)
    
    def _print_transaction_summary(
        self,
        erc20_count: int,
        t12_count: int,
        matched_count: int,
        erc20_rollback_count: int,
        t12_rollback_count: int
    ):
        """Print transaction summary statistics"""
        erc20_net = erc20_count - erc20_rollback_count
        t12_net = t12_count - t12_rollback_count
        
        print("📈 TRANSACTION SUMMARY:")
        print(f"├─ 🔗 ERC20 transactions: {erc20_net:,} "
              f"(excluded {erc20_rollback_count} rollback txs)")
        print(f"├─ ⛓️ T12 transactions: {t12_net:,} "
              f"(excluded {t12_rollback_count} rollback txs)")
        print(f"├─ ✅ Successfully matched pairs: {matched_count:,}")
        
        # Get final inconsistent count from file
        self._print_inconsistent_count()
        
        # Calculate match rate
        if max(erc20_net, t12_net) > 0:
            match_rate = (matched_count / max(erc20_net, t12_net)) * 100
            print(f"📊 Overall match rate: {match_rate:.2f}%")
        
        print("-" * 60)
    
    def _print_inconsistent_count(self):
        """Print inconsistent transaction count"""
        try:
            filepath = self.config.inconsistent_transactions_file
            if filepath.exists():
                df = pd.read_csv(filepath)
                if not df.empty:
                    final_count = len(df)
                    erc20_inc = len(df[df['chain'] == Chain.ERC20.value])
                    t12_inc = len(df[df['chain'] == Chain.T12.value])
                    print(f"└─ ❌ Final inconsistent transactions: {final_count:,}")
                    print(f"   ├─ ERC20: {erc20_inc:,}")
                    print(f"   └─ T12: {t12_inc:,}")
                else:
                    print("└─ ❌ Final inconsistent transactions: 0")
            else:
                print("└─ ❌ Final inconsistent transactions: 0")
        except Exception as e:
            logger.warning(f"Could not read inconsistent transactions file: {e}")
            print("└─ ❌ Inconsistent transactions: (see file)")
    
    def _print_bridge_balance_analysis(
        self,
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance]
    ):
        """
        Print bridge address balance analysis with explanation
        
        Args:
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
        """
        bridge_addr = self.config.bridge_address.lower()
        
        print("\n🌉 BRIDGE ADDRESS BALANCE ANALYSIS:")
        
        if bridge_addr in erc20_balances or bridge_addr in t12_balances:
            erc20_bal = erc20_balances.get(bridge_addr, WalletBalance())
            t12_bal = t12_balances.get(bridge_addr, WalletBalance())
            
            diff_net_balance = erc20_bal.net_balance + t12_bal.net_balance
            
            print(f"├─ Bridge Address: {self.config.bridge_address}")
            print(f"├─ ERC20 Net Balance: {erc20_bal.net_balance:.8f} TET")
            print(f"├─ T12 Net Balance: {t12_bal.net_balance:.8f} TET")
            print(f"└─ Combined Diff Net Balance: {diff_net_balance:.8f} TET")
            
            print(f"\n💡 BRIDGE BALANCE EXPLANATION:")
            print(f"   The diff_net_balance represents the difference between what the T12")
            print(f"   bridge received and what the ERC20 bridge sent to wallets, calculated")
            print(f"   from {self.config.fetch_start_date.strftime('%Y-%m-%d')} onwards, after removing all rollback transactions.")
            print(f"   A positive value indicates more TET received on T12 than sent from ERC20.")
            print(f"   A negative value indicates more TET sent from ERC20 than received on T12.")
        else:
            print("└─ Bridge address not found in balance calculations")
        
        print("-" * 60)
    
    def _print_wallet_analysis(self, chain: str, balances: Dict[str, WalletBalance]):
        """
        Print wallet analysis for a specific chain
        
        Args:
            chain: Chain name
            balances: Wallet balances dictionary
        """
        if not balances:
            return
        
        total_wallets = len(balances)
        total_sent = sum(bal.sent for bal in balances.values())
        total_received = sum(bal.received for bal in balances.values())
        total_sent_txs = sum(bal.sent_count for bal in balances.values())
        total_received_txs = sum(bal.received_count for bal in balances.values())
        
        print(f"\n💰 {chain} WALLET ANALYSIS:")
        print(f"├─ 👛 Total unique wallets: {total_wallets:,}")
        print(f"├─ 📤 Total TET sent from bridge: {total_sent:.8f} ({total_sent_txs:,} txs)")
        print(f"├─ 📥 Total TET received by bridge: {total_received:.8f} ({total_received_txs:,} txs)")
        print(f"└─ ⚖️ Net bridge balance: {total_received - total_sent:.6f}")
        print("-" * 60)
    
    def _print_top_wallets(
        self,
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance]
    ):
        """
        Print top 10 wallets by erc20_net_balance (excluding bridge address)
        
        Args:
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
        """
        bridge_addr = self.config.bridge_address.lower()
        
        # Combine all wallets
        all_wallets = set(erc20_balances.keys()) | set(t12_balances.keys())
        
        # Exclude bridge address
        all_wallets = all_wallets - {bridge_addr}
        
        # Create list with erc20_net_balance
        wallet_data = []
        for wallet in all_wallets:
            erc20_bal = erc20_balances.get(wallet, WalletBalance())
            wallet_data.append({
                'address': wallet,
                'erc20_net_balance': erc20_bal.net_balance
            })
        
        # Sort by erc20_net_balance (descending)
        wallet_data.sort(key=lambda x: x['erc20_net_balance'], reverse=True)
        
        # Get top 10
        top_10 = wallet_data[:10]
        
        print("\n🏆 TOP 10 WALLETS BY ERC20 NET BALANCE (excluding bridge):")
        
        if top_10:
            for idx, wallet_info in enumerate(top_10, 1):
                addr = wallet_info['address']
                erc20_net = wallet_info['erc20_net_balance']
                
                # Get T12 balance for additional context
                t12_bal = t12_balances.get(addr, WalletBalance())
                t12_net = t12_bal.net_balance
                diff_net = erc20_net + t12_net
                
                print(f"{idx:2d}. {addr}")
                print(f"    ├─ ERC20 Net: {erc20_net:>15.8f} TET")
                print(f"    ├─ T12 Net:   {t12_net:>15.8f} TET")
                print(f"    └─ Diff Net:  {diff_net:>15.8f} TET")
        else:
            print("   No wallets found (excluding bridge address)")
        
        print("-" * 60)
        
    def _print_explanation(self):
        """Print explanation of signed amounts"""
        print("-" * 60)
        print("💡 SIGNED AMOUNTS EXPLANATION:")
        print("├─ ➕ Positive amounts: Incoming to bridge (deposits)")
        print("├─ ➖ Negative amounts: Outgoing from bridge (withdrawals)")
        print("└─ 📊 This helps identify bridge flow direction")
    
    def _print_detection_window(self):
        """Print detection window configuration"""
        print("-" * 60)
        print("🔄 DETECTION WINDOW:")
        print(f"├─ ⏱️ Fetching start date: "
              f"{self.config.fetch_start_date.strftime('%Y/%m/%d %H:%M:%S')}")
        print(f"├─ ⏱️ Matching tolerance: "
              f"{self.config.timestamp_tolerance / 3600:.1f} hours")
        print(f"├─ ⏱️ Rollback tolerance: "
              f"{self.config.rollback_tolerance / 3600:.1f} hours")
        print(f"└─ 💰 Amount tolerance: {self.config.amount_tolerance}")
    
    def _print_output_files(self):
        """Print output file paths"""
        print("-" * 60)
        print("📁 OUTPUT FILES:")
        print(f"├─ 🔗 ERC20 transactions: {self.config.erc20_transactions_file.name}")
        print(f"├─ ⛓️ T12 transactions: {self.config.t12_transactions_file.name}")
        print(f"├─ 💰 Wallet balances: {self.config.wallet_balances_file.name}")
        print(f"├─ ✅ Matched transactions: {self.config.matched_transactions_file.name}")
        print(f"├─ ❌ Inconsistent transactions: {self.config.inconsistent_transactions_file.name}")
        print(f"└─ 🔄 Removed rollback pairs: {self.config.erc20_rollback_file.name}, "
              f"{self.config.t12_rollback_file.name}")
        print("-" * 60)


# ==================== MAIN ANALYZER ====================

class TETBridgeAnalyzer:
    """Main analyzer orchestrating all components"""
    
    def __init__(self, config: AnalyzerConfig = None):
        """
        Initialize TET Bridge Analyzer
        
        Args:
            config: Analyzer configuration (uses default if None)
        """
        self.config = config or AnalyzerConfig()
        self.api_client = APIClient(timeout=self.config.api_timeout)
        self.fetcher = TransactionFetcher(self.config, self.api_client)
        self.processor = TransactionProcessor(self.config)
        self.balance_calculator = WalletBalanceCalculator(self.config)
        self.file_manager = FileManager(self.config)
        self.report_generator = ReportGenerator(self.config)
        
        self._print_startup_banner()
    
    def _print_startup_banner(self):
        """Print startup banner with configuration info"""
        print("=" * 60)
        print("🚀 TET BRIDGE ANALYZER STARTING...")
        print("=" * 60)
        
        logger.info("TET Bridge Analyzer initialized")
        logger.info(f"Bridge address: {self.config.bridge_address}")
        logger.info(f"TET token contract: {self.config.tet_token_address}")
        logger.info(f"Amount tolerance: {self.config.amount_tolerance}")
        logger.info("Amount signs: Positive = incoming, Negative = outgoing")
    
    def run_analysis(self):
        """Execute the complete analysis pipeline"""
        total_start_time = time.time()
        print("\n" + "=" * 60)
        print("🚀 TET BRIDGE CONSISTENCY ANALYSIS STARTING")
        print("=" * 60)
        
        try:
            # Execute analysis steps
            self._step1_initialize_files()
            erc20_txs, t12_txs = self._step2_fetch_transactions()
            matched_pairs, erc20_inconsistent, t12_inconsistent = self._step3_match_transactions(
                erc20_txs, t12_txs
            )
            final_inconsistent, erc20_removed_pairs, t12_removed_pairs = self._step4_detect_rollbacks(
                erc20_inconsistent, t12_inconsistent
            )
            erc20_balances, t12_balances = self._step5_calculate_balances(
                erc20_txs, t12_txs, erc20_removed_pairs, t12_removed_pairs
            )
            self._step6_save_results(
                matched_pairs, final_inconsistent,
                erc20_balances, t12_balances,
                erc20_removed_pairs, t12_removed_pairs
            )
            self._step7_generate_report(
                erc20_txs, t12_txs, matched_pairs, final_inconsistent,
                erc20_balances, t12_balances,
                erc20_removed_pairs, t12_removed_pairs
            )
            
            # Print completion message
            total_elapsed = time.time() - total_start_time
            print(f"\n🎉 ANALYSIS COMPLETED in {total_elapsed:.2f} seconds")
            print("=" * 60)
            
        except KeyboardInterrupt:
            print("\n⚠️ Analysis interrupted by user")
            logger.warning("Analysis interrupted by user")
        except Exception as e:
            logger.error(f"Analysis failed: {str(e)}", exc_info=True)
            print(f"\n❌ ANALYSIS FAILED: {str(e)}")
            raise
        finally:
            self.api_client.close()
    
    def _step1_initialize_files(self):
        """Step 1: Initialize CSV files"""
        print("\n📁 STEP 1: INITIALIZE CSV FILES")
        self.file_manager.initialize_csv_files()
    
    def _step2_fetch_transactions(self) -> Tuple[List[Transaction], List[Transaction]]:
        """
        Step 2: Fetch transactions from both chains
        
        Returns:
            Tuple of (erc20_transactions, t12_transactions)
        """
        print("\n📡 STEP 2: FETCH TRANSACTIONS")
        print("💡 Note: Positive amounts = incoming, Negative = outgoing")
        print("🗑️ Zero amount transactions filtered automatically")
        
        erc20_txs = self.fetcher.fetch_erc20_transactions()
        t12_txs = self.fetcher.fetch_t12_transactions()
        
        # Save raw transactions
        self.file_manager.save_transactions(erc20_txs, self.config.erc20_transactions_file)
        self.file_manager.save_transactions(t12_txs, self.config.t12_transactions_file)
        
        return erc20_txs, t12_txs
    
    def _step3_match_transactions(
        self,
        erc20_txs: List[Transaction],
        t12_txs: List[Transaction]
    ) -> Tuple[List[Dict], List[Transaction], List[Transaction]]:
        """
        Step 3: Match transactions between chains
        
        Args:
            erc20_txs: ERC20 transactions
            t12_txs: T12 transactions
            
        Returns:
            Tuple of (matched_pairs, erc20_inconsistent, t12_inconsistent)
        """
        print("\n🔄 STEP 3: MATCH TRANSACTIONS")
        return self.processor.match_transactions(erc20_txs, t12_txs)
    
    def _step4_detect_rollbacks(
        self,
        erc20_inconsistent: List[Transaction],
        t12_inconsistent: List[Transaction]
    ) -> Tuple[List[Transaction], List[RollbackPair], List[RollbackPair]]:
        """
        Step 4: Detect and remove rollback transactions
        
        Args:
            erc20_inconsistent: Inconsistent ERC20 transactions
            t12_inconsistent: Inconsistent T12 transactions
            
        Returns:
            Tuple of (final_inconsistent, erc20_removed_pairs, t12_removed_pairs)
        """
        print("\n🔄 STEP 4: DETECT AND REMOVE ROLLBACK TRANSACTIONS")
        
        erc20_filtered, erc20_removed_pairs = self.processor.remove_rollback_transactions(
            erc20_inconsistent, Chain.ERC20
        )
        t12_filtered, t12_removed_pairs = self.processor.remove_rollback_transactions(
            t12_inconsistent, Chain.T12
        )
        
        # Combine filtered inconsistent transactions
        final_inconsistent = erc20_filtered + t12_filtered
        
        print(f"\n✅ Final inconsistent transactions after rollback removal: "
              f"{len(final_inconsistent):,}")
        print(f"   ├─ ERC20: {len(erc20_filtered):,}")
        print(f"   └─ T12: {len(t12_filtered):,}")
        
        return final_inconsistent, erc20_removed_pairs, t12_removed_pairs
    
    def _step5_calculate_balances(
        self,
        erc20_txs: List[Transaction],
        t12_txs: List[Transaction],
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ) -> Tuple[Dict[str, WalletBalance], Dict[str, WalletBalance]]:
        """
        Step 5: Calculate wallet balances
        
        Args:
            erc20_txs: ERC20 transactions
            t12_txs: T12 transactions
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs
            
        Returns:
            Tuple of (erc20_balances, t12_balances)
        """
        print("\n💰 STEP 5: CALCULATE WALLET BALANCES")
        return self.balance_calculator.calculate_balances(
            erc20_txs, t12_txs, erc20_removed_pairs, t12_removed_pairs
        )
    
    def _step6_save_results(
        self,
        matched_pairs: List[Dict],
        final_inconsistent: List[Transaction],
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance],
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ):
        """
        Step 6: Save all results to files
        
        Args:
            matched_pairs: Matched transaction pairs
            final_inconsistent: Final inconsistent transactions
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs
        """
        print("\n💾 STEP 6: SAVE RESULTS")
        self.file_manager.save_matched_transactions(matched_pairs)
        self.file_manager.save_inconsistent_transactions(final_inconsistent)
        self.file_manager.save_wallet_balances(erc20_balances, t12_balances)
        self.file_manager.save_rollback_pairs(erc20_removed_pairs, t12_removed_pairs)
    
    def _step7_generate_report(
        self,
        erc20_txs: List[Transaction],
        t12_txs: List[Transaction],
        matched_pairs: List[Dict],
        final_inconsistent: List[Transaction],
        erc20_balances: Dict[str, WalletBalance],
        t12_balances: Dict[str, WalletBalance],
        erc20_removed_pairs: List[RollbackPair],
        t12_removed_pairs: List[RollbackPair]
    ):
        """
        Step 7: Generate summary report
        
        Args:
            erc20_txs: ERC20 transactions
            t12_txs: T12 transactions
            matched_pairs: Matched transaction pairs
            final_inconsistent: Final inconsistent transactions
            erc20_balances: ERC20 wallet balances
            t12_balances: T12 wallet balances
            erc20_removed_pairs: ERC20 rollback pairs
            t12_removed_pairs: T12 rollback pairs
        """
        print("\n📊 STEP 7: GENERATE REPORT")
        self.report_generator.generate_summary(
            len(erc20_txs),
            len(t12_txs),
            len(matched_pairs),
            len(final_inconsistent),
            erc20_balances,
            t12_balances,
            len(erc20_removed_pairs) * 2,  # Each pair contains 2 transactions
            len(t12_removed_pairs) * 2
        )


# ==================== MAIN ENTRY POINT ====================

def main():
    """Main execution function"""
    print("🚀 TET BRIDGE ANALYZER")
    print("=" * 40)
    
    # Check environment variables
    if not os.getenv('ETHERSCAN_API_KEY'):
        print("⚠️ ETHERSCAN_API_KEY not set - using default (may have rate limits)")
        print("💡 Set ETHERSCAN_API_KEY environment variable for better limits")
    else:
        print("✅ ETHERSCAN_API_KEY found")
    
    # Initialize and run analyzer
    try:
        config = AnalyzerConfig()
        analyzer = TETBridgeAnalyzer(config)
        analyzer.run_analysis()
    except Exception as e:
        logger.error(f"Fatal error: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
